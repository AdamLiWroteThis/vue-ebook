<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><title>Challenges and Strategies for Undertaking Continuous Experimentation to Embedded Systems: Industry and Research Perspectives</title><link href="springer_epub.css" type="text/css" rel="styleSheet"/></head><body><div class="ChapterContextInformation"><div class="ContextInformation" id="Chap20"><div class="ChapterCopyright">© The Author(s) 2018</div><span class="ContextInformationAuthorEditorNames"><span class="Editor"><span class="EditorName">Juan Garbajosa</span>, </span><span class="Editor"><span class="EditorName">Xiaofeng Wang</span> and </span><span class="Editor"><span class="EditorName">Ademar Aguiar</span></span><span class="CollaboratorDesignation"> (eds.)</span></span><span class="ContextInformationBookTitles"><span class="BookTitle" xml:lang="en">Agile Processes in Software Engineering and Extreme Programming</span></span><span class="ContextInformationSeries"><span class="SeriesTitle" xml:lang="en">Lecture Notes in Business Information Processing</span><span class="ContextInformationVolumeNumber">314</span></span><span class="ChapterDOI"><a href="A468350_1_En_20_Chapter.html">https://doi.org/10.1007/978-3-319-91602-6_20</a></span></div></div><!--Begin Abstract--><div class="MainTitleSection"><h1 class="ChapterTitle" xml:lang="en">Challenges and Strategies for Undertaking Continuous Experimentation to Embedded Systems: Industry and Research Perspectives</h1></div><div class="AuthorGroup"><div class="AuthorNames"><span class="Author"><span class="AuthorName">David Issa Mattos</span><sup>1 <a href="#ContactOfAuthor1"><span class="ContactIcon"> </span></a></sup>, </span><span class="Author"><span class="AuthorName">Jan Bosch</span><sup>1 <a href="#ContactOfAuthor2"><span class="ContactIcon"> </span></a></sup> and </span><span class="Author"><span class="AuthorName">Helena Holmström Olsson</span><sup>2 <a href="#ContactOfAuthor3"><span class="ContactIcon"> </span></a></sup></span></div><div class="Affiliations"><div class="Affiliation" id="Aff9"><span class="AffiliationNumber">(1)</span><div class="AffiliationText">Department of Computer Science and Engineering, Chalmers University of Technology, Hörselgången 11, 412 96 Göteborg, Sweden</div></div><div class="Affiliation" id="Aff10"><span class="AffiliationNumber">(2)</span><div class="AffiliationText">Department of Computer Science and Media Technology, Malmö University, Nordenskiöldsgatan, 211 19 Malmö, Sweden</div></div><div class="ClearBoth"> </div></div><div class="Contacts"><div class="Contact" id="ContactOfAuthor1"><div class="ContactIcon"> </div><div class="ContactAuthorLine"><span class="AuthorName">David Issa Mattos</span> (Corresponding author)</div><div class="ContactAdditionalLine"><span class="ContactType">Email: </span><a href="mailto:davidis@chalmers.se" class="Email">davidis@chalmers.se</a></div></div><div class="Contact" id="ContactOfAuthor2"><div class="ContactIcon"> </div><div class="ContactAuthorLine"><span class="AuthorName">Jan Bosch</span></div><div class="ContactAdditionalLine"><span class="ContactType">Email: </span><a href="mailto:jan.bosch@chalmers.se" class="Email">jan.bosch@chalmers.se</a></div></div><div class="Contact" id="ContactOfAuthor3"><div class="ContactIcon"> </div><div class="ContactAuthorLine"><span class="AuthorName">Helena Holmström Olsson</span></div><div class="ContactAdditionalLine"><span class="ContactType">Email: </span><a href="mailto:helena.holmstrom.olsson@mah.se" class="Email">helena.holmstrom.olsson@mah.se</a></div></div></div></div><div class="Abstract" id="Abs1" xml:lang="en"><div class="Heading">Abstract</div><div id="Par1" class="Para"><span class="EmphasisTypeBold">Context</span>: Continuous experimentation is frequently used in web-facing companies and it is starting to gain the attention of embedded systems companies. However, embedded systems companies have different challenges and requirements to run experiments in their systems. <span class="EmphasisTypeBold">Objective</span>: This paper explores the challenges during the adoption of continuous experimentation in embedded systems from both industry practice and academic research. It presents strategies, guidelines, and solutions to overcome each of the identified challenges. <span class="EmphasisTypeBold">Method</span>: This research was conducted in two parts. The first part is a literature review with the aim to analyze the challenges in adopting continuous experimentation from the research perspective. The second part is a multiple case study based on interviews and workshop sessions with five companies to understand the challenges from the industry perspective and how they are working to overcome them. <span class="EmphasisTypeBold">Results</span>: This study found a set of twelve challenges divided into three areas; technical, business, and organizational challenges and strategies grouped into three categories, architecture, data handling and development processes. <span class="EmphasisTypeBold">Conclusions</span>: The set of identified challenges are presented with a set of strategies, guidelines, and solutions. To the knowledge of the authors, this paper is the first to provide an extensive list of challenges and strategies for continuous experimentation in embedded systems. Moreover, this research points out open challenges and the need for new tools and novel solutions for the further development of experimentation in embedded systems.</div></div><div class="KeywordGroup" xml:lang="en"><div class="Heading">Keywords</div><span class="Keyword">Continuous experimentation</span><span class="Keyword">Data-driven development</span><span class="Keyword">Controlled experiments</span><span class="Keyword">Embedded systems</span></div><!--End Abstract--><div class="Fulltext"><div id="Sec1" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">1 </span>Introduction</h2><div id="Par2" class="Para">Traditional embedded systems companies continuously rely on software to be a differentiator on their products. As the software size of the products increases, these companies are moving from being mechanical producers to software companies. In their development process, these companies traditionally make use of up-front requirements and rigid methodologies to ensure quality or safety attributes in their products. Nevertheless, the requirements of several parts of their systems are not clear or cannot be defined in advance [<cite><a href="#CR1">1</a></cite>]. In this context, developers either negotiate with requirement teams or they make implicit assumptions about the requirements [<cite><a href="#CR2">2</a></cite>].</div><div id="Par3" class="Para">Even during the requirement specification, several requirements are written based on assumptions and does not necessarily deliver value to the company or the customers. Often, research and development effort is spent on features that are never or rarely used [<cite><a href="#CR3">3</a></cite>] by the users of the product. To minimize the full development of features that do not deliver value, companies make use of post-deployment data of current products to iterate in future software releases or in even in new products. In the web domain, companies provide empirical evidence of the use of continuous experimentation in their development, decision-making and feature prioritization process [<cite><a href="#CR4">4</a></cite>–<cite><a href="#CR6">6</a></cite>].</div><div id="Par4" class="Para">As software becomes the key differentiator for many embedded systems companies, these companies started to adopt continuous development practices, such as continuous integration, deployment, and experimentation to develop faster, better and more cost-effective products. A typical pattern that companies follow is shown in the “Stairway to Heaven” model [<cite><a href="#CR7">7</a></cite>]. When these companies start to move to move to continuous deployment scenarios, they see opportunities to run their first experiments as well.</div><div id="Par5" class="Para">Although the research in continuous experimentation in web systems is continually growing, there are few examples of works investigating the use of continuous experimentation in embedded systems.</div><div id="Par6" class="Para">This paper identifies and analyzes the different challenges that embedded systems companies face when adopting continuous experimentation in their development processes. Moreover, it also presents strategies, guidelines, and potential solutions to overcome each of the identified challenges.</div><div id="Par7" class="Para">The scope of this research is captured with the following research question.</div><div id="Par8" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeBold">RQ</span>: How can embedded systems industry adopt continuous experimentation in their development process?</div><div id="Par9" class="Para">This research question is further developed in terms of the following sub-questions:</div><div id="Par10" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeBold">RQ1</span>: What are the recognized challenges towards continuous experimentation faced by the embedded systems industry?</div><div id="Par11" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeBold">RQ2</span>: What are the recommended strategies to facilitate the use of continuous experimentation in the embedded systems domain?</div><div id="Par12" class="Para">The contribution of this paper is twofold. First, it identifies the key challenges faced by embedded systems companies when adopting continuous experimentation. These challenges are identified from both the industry perspective, through a multi-company case study, and the academic perspective, through a literature review. Second, this paper proposes different strategies and guidelines to overcome the identified challenges. This paper, to the knowledge of the authors, is the first to present an extensive set of challenges and strategies that embedded systems companies face when adopting continuous experimentation. Moreover, the analysis of the challenges points out the need for new tools and novel solutions for the further development of experimentation in embedded systems.</div><div id="Par13" class="Para">The rest of the paper is organized as follows. Section <span class="InternalRef"><a href="#Sec2">2</a></span> provides a background review in continuous experimentation. Section <span class="InternalRef"><a href="#Sec3">3</a></span> presents the research method. Section <span class="InternalRef"><a href="#Sec6">4</a></span> presents and discusses the results in the form of identified challenges and suggested strategies. Section <span class="InternalRef"><a href="#Sec10">5</a></span> discusses the validity threats of this research. Section <span class="InternalRef"><a href="#Sec11">6</a></span> concludes and discusses research challenges and future works.</div></div><div id="Sec2" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">2 </span>Background</h2><div id="Par14" class="Para">Continuous experimentation refers to the research and application of controlled experimentation to drive software development, for reliably evaluate and prioritize development activities [<cite><a href="#CR4">4</a></cite>].</div><div id="Par15" class="Para">Studies show that the prioritization of features is traditionally driven by past experiences, beliefs, and organizational role [<cite><a href="#CR6">6</a></cite>, <cite><a href="#CR8">8</a></cite>]. The decision to invest development resources in a full feature can result in inefficiency and opportunity cost if the feature does not have a confirmed value [<cite><a href="#CR9">9</a></cite>]. Companies traditionally rely on customers interviews and qualitative studies to derive requirements for the system in the early stages of the development [<cite><a href="#CR10">10</a></cite>]. However, customers usually are not good in predicting what they want or they are not aware of other potential solutions [<cite><a href="#CR1">1</a></cite>].</div><div id="Par16" class="Para">In the post-deployment stage, companies usually collect customer and product data. Most software companies, from both the embedded and web systems domains collects and logs usage and operational data [<cite><a href="#CR10">10</a></cite>]. In embedded systems, these log data are mostly used for troubleshooting and improving subsequent products. However, over the last decade, software companies are showing an increasing interest in using the collected data to improve not only future products but also to improve the current products.</div><div id="Par17" class="Para">Recent technological trends focus on not only identifying and solve technical problems but also delivering value to their customers and users [<cite><a href="#CR11">11</a></cite>]. The Lean Startup methodology proposes the cycle build-measure-learn [<cite><a href="#CR12">12</a></cite>]. In this methodology, the collected post-deployment data is also used in the improvement of the current product. The HYPEX model [<cite><a href="#CR9">9</a></cite>] presents an approach to shorten the feedback loop between companies and customers. The model uses hypotheses, customer feedback and the minimum viable product (MVP) to continuously decide upon the full development or abandonment of a feature.</div><div id="Par18" class="Para">Web-facing companies continuously report the use of post-deployment data and controlled experiments to develop and continuously improve their systems. The uncertainty raised by the environment, interaction with humans and other agents impact in the system behavior in unknown and unpredictable ways. Controlled experiments help companies to establish the causal relationship between a variation in their system and the observed behavior [<cite><a href="#CR6">6</a></cite>].</div><div id="Par19" class="Para">In software development, A/B test is the simplest version of a controlled experiment. “A” stands for the control variation and “B” stands for the treatment variation. The treatment (variation “B”) represents any point in the system that you want to modify and compare to the control (variation “A”). Both variations are deployed to randomized users, to avoid bias, and the analyzed behavior is the measured in both cases. Statistical analysis helps to determine if there is a causal difference between the observed behavior and the variations. Other experimentation techniques are described in [<cite><a href="#CR6">6</a></cite>].</div><div id="Par20" class="Para">Kohavi et al. [<cite><a href="#CR6">6</a></cite>] provides a guide on how to run controlled experiments in web systems. The paper discusses the important ingredients, limitations of experimentation, architectures for experimentation systems, how to analyze and how to design controlled experiments for the web. Kohavi et al. [<cite><a href="#CR13">13</a></cite>], presents some rules of thumb and common pitfalls when running experimentation, such as iterating in the experiment design, the impact of speed and performance, number of users and how experiments impact key metrics.</div><div id="Par21" class="Para">Fagerholm et al. [<cite><a href="#CR11">11</a></cite>] provides a general infrastructure for running continuous experimentation systematically. The RIGHT framework describes how to design and manage experiments, and how different stakeholders (business analyst, product owner, data scientists, developers, and DevOps engineers) interact with an experimentation infrastructure.</div><div id="Par22" class="Para">Fabijan et al. [<cite><a href="#CR4">4</a></cite>] describes the Experimentation Evolution Model, based on experimentation at Microsoft. This model analyzes how teams scale their experimentation from a few experiments to a data-driven organization. The model divides this evolution into four steps: crawl (teams are running and setting their first experiments), walk (teams already run a few experiments and determining metrics and experimentation platforms), run (the teams run several experiments and iterate quickly to identify effects of experiments on the business) and fly (experiments are the norm for every change to any product). Each of these phases is discussed in three different perspectives, the technical, the organizational, and the business perspectives.</div><div id="Par23" class="Para">One of the challenges in controlled experiments is defining an Overall Evaluation Metric (OEC) [<cite><a href="#CR4">4</a></cite>, <cite><a href="#CR6">6</a></cite>, <cite><a href="#CR14">14</a></cite>]. The OEC is a quantitative measure of the experiment’s objective. It provides a balance between short and long-term effects considering the business objectives. Olsson and Bosch [<cite><a href="#CR14">14</a></cite>], present a systematic approach to model the value of experiments. This approach allows companies that are starting to run the first experiments to understand and improve their own OEC metrics.</div><div id="Par24" class="Para">To the knowledge of the authors, the first research discussing the experiments in embedded systems appeared in 2012 [<cite><a href="#CR15">15</a></cite>]. This paper discusses experimentation in the context of Innovation Experiment Systems. It identifies some challenges with experimentation in embedded systems, such as experimentation in safety systems, managing multiple stakeholders and hardware limitations. It also presents an initial infrastructure to run experiments in embedded systems.</div><div id="Par25" class="Para">Giaimo and Berger [<cite><a href="#CR16">16</a></cite>], discuss continuous experimentation in the context of self-driving vehicles. The paper presents functional (such as instrumentation, logging, data feedback to a remote server) and non-functional (separation of concerns, safety, short cycle to deployment) requirements to achieve continuous software evolution. Bosch and Olsson [<cite><a href="#CR17">17</a></cite>], extended the concept of experimentation towards automated experimentation. Automated experimentation aims to leverage the number of experiments by letting the system own and control the experiments, opposed to the R&amp;D organization. Mattos et al. [<cite><a href="#CR18">18</a></cite>, <cite><a href="#CR19">19</a></cite>], identified a set of architectural qualities to support automated experimentation that was implemented in a research mobile autonomous vehicle.</div></div><div id="Sec3" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">3 </span>Research Method</h2><div id="Par26" class="Para">The research process used in this study combines a literature review with multiple case study. This research method aims to strengthen the evidence of the challenges and strategies found in a multiple case-study with others found in the research literature. Research in continuous experimentation generally utilizes the case study as the research method, combining results from both approaches reinforce the empirical evidence of the findings.</div><div id="Par27" class="Para">The method is composed of two parts. The first part consists of a literature review in the continuous experimentation domain. This literature review collects challenges and strategies to overcome them from academic research. The second part consists of semi-structured interviews with software companies in the embedded systems domain. It aims to be exploratory, collect and confirm challenges and strategies from the embedded systems industry. Below, the research method is described in details. The results of both parts were aggregated and described in Sect. <span class="InternalRef"><a href="#Sec6">4</a></span>. Table <span class="InternalRef"><a href="#Tab1">1</a></span> summarizes the research process used in this paper.<div id="Tab1" class="Table"><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 1.</span><div class="SimplePara">Summary of the research method. LR stands for the literature review part and CS for the multiple case study part.</div></div></div><table border="1"><colgroup><col align="left"/><col align="left"/></colgroup><thead><tr class="header"><th align="left"><div class="SimplePara">Step</div></th><th align="left"><div class="SimplePara">Description</div></th></tr></thead><tbody><tr class="noclass"><td align="left"><div class="SimplePara">1</div></td><td align="left"><div class="SimplePara">Search definition and execution (LR)</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">2</div></td><td align="left"><div class="SimplePara">Papers review (LR)</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">Identification of literature challenges and strategies (LR)</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">4</div></td><td align="left"><div class="SimplePara">Data selection: Contact with companies (CS)</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">5</div></td><td align="left"><div class="SimplePara">Semi-structured interview protocol definition (CS)</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">6</div></td><td align="left"><div class="SimplePara">Data collection: Interviews and workshop (CS)</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">7</div></td><td align="left"><div class="SimplePara">Data analysis: thematic coding and categorization (CS)</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">8</div></td><td align="left"><div class="SimplePara">Case study report (CS)</div></td></tr></tbody></table></div>
</div><div id="Sec4" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">3.1 </span>Literature Review</h3><div id="Par28" class="Para">The first part of the research method consists of a literature review in continuous experimentation. Although most of the studies in continuous experimentation focus on web-facing companies, the experiences from this domain, sometimes, can be extrapolated to the embedded systems domain. In this literature review, the authors identified challenges recognized in academic collaboration with industry, regardless of the industry domain. The identified challenges were discussed with the embedded systems companies to see if the literature challenges were also relevant in this domain.</div><div id="Par29" class="Para">
Relevant works in the literature covering continuous experimentation were identified by searching the Scopus digital indexing library, by keywords, title and abstract. The used search phrase was “((continuous experimentation) OR (field experiments) OR (innovation experiment systems)) AND (software engineering)’’. This search query was restricted to the fields of engineering and computer science and limited from 2000 to 2017. This search phrase resulted in 534 articles. Positioning papers and papers with less than 5 pages were excluded. From this subset of articles, the results were filtered based on the abstract. After the first screening process, the papers were read in their integrity. Continuous experimentation is also largely studied from the statistical/algorithmic side. Research papers that focused solely on improving or evaluating algorithms without industry evaluation or application were excluded.</div><div id="Par30" class="Para">After this screening process, the authors identified 30 articles with relevance to this study. An additional set of 12 articles were included using a snowballing [<cite><a href="#CR20">20</a></cite>] process, where new references were added according to the references mentioned in the other articles. Thematic coding was used to [<cite><a href="#CR21">21</a></cite>] identify the challenges from the literature. These challenges were categorized according to the three different categories of the Experimentation Evolution Model [<cite><a href="#CR4">4</a></cite>] discussed in Sect. <span class="InternalRef"><a href="#Sec2">2</a></span>, the technical, the organizational and the business perspective. The identified set of challenges were also used as input for the semi-structured interviews as discussed in Sect. <span class="InternalRef"><a href="#Sec5">3.2</a></span>. The strategies are categorized in three groups: changes in the development process, changes in the system’s architecture and changes in how the experiment and organizational data is handled and analyzed.</div><div id="Par31" class="Para">The complete set of papers can be found at the following link: <span class="ExternalRef"><a href="https://github.com/davidissamattos/public_documents/blob/master/LR-XP18.png"><span class="RefSource">https://​github.​com/​davidissamattos/​public_​documents/​blob/​master/​LR-XP18.​png</span></a></span>.</div><div id="Par32" class="Para">This part of the research process allowed the identification of challenges that served as input for the multiple case study and confirmation of identified challenges inside the company.</div></div><div id="Sec5" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">3.2 </span>Multiple Case Study</h3><div id="Par33" class="Para">The second part of the research method consists of a multiple case study [<cite><a href="#CR21">21</a></cite>] with semi-structured interviews conducted with software companies in the embedded systems domain. This study was conducted from December 2016 to October 2017 with five companies in the embedded systems domain. The empirical data consists of interviews and a workshops transcripts and notes. There were 8 individual semi-structured interviews with an average of one hour each, three in <span class="EmphasisTypeItalic">Company A</span>, two in <span class="EmphasisTypeItalic">Company B</span>, one in <span class="EmphasisTypeItalic">Company C,</span> one in <span class="EmphasisTypeItalic">Company D</span> and 2 in <span class="EmphasisTypeItalic">Company E</span>. The workshop session was conducted with 8 people from <span class="EmphasisTypeItalic">Company A</span> lasting 3 h. The analysis of the empirical data consisted of thematic coding of [<cite><a href="#CR21">21</a></cite>] interviews transcriptions and notes to identify and categorize the challenges and solutions. Additionally, during the interviews challenges identified in the literature were clarified to the interviews and asked if the current company relates to the challenge partially or not.</div><div id="Par34" class="Para">The empirical data were aggregated together with the identified challenges and strategies from the literature review. The current published research already provides guidelines and solutions for the challenges that were also identified in the literature review phase. Other guidelines and solutions were suggested by practitioners during the interviews. Challenges identified in the literature that was not confirmed neither through a previous case study nor by the case study companies are not shown.</div><div id="Par35" class="Para">Due to confidentiality reasons, only a short description of each company and their domain is provided:</div><div id="Par36" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeItalic">Company A</span> is a multinational conglomerate company that manufactures embedded systems and electronics and provides software solutions for both consumers and professionals. This study was conducted with two teams, one providing mobile communications solutions and the other providing business-to-business products. In recent years, the company started to adopt experimentation in their software solutions and is looking for data-driven strategies in their embedded systems products. The interviewees were developers, managers and data analysts.</div><div id="Par37" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeItalic">Company B</span> is a multinational company that provides telecommunication and networking systems. The company is adopting continuous development practices and is looking for new strategies to deliver more value to their customers by optimizing their products. The interviewees were managers.</div><div id="Par38" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeItalic">Company C</span> is a global automotive manufacturer and supplier of transport solutions. As the company’s products are continuously growing in complexity and software size, the company is looking for strategies to prioritize their R&amp;D effort and deliver more value to their customers. As some employees have experience in web and pure software-systems development, experimentation is getting attention in some development teams. Challenges in experimentation arise since the company is subjected to several regulations and certification procedures. The interviewee was a senior engineer.</div><div id="Par39" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeItalic">Company D</span> is a global software company that develops and provides embedded systems software solutions related to autonomous driving technology for the automotive industry. Autonomous driving is an emerging and fast-moving technology and the company is looking to deliver competitive solutions faster by adopting continuous development practices. However, as it interfaces with the highly regulated automotive domain its software is also subjected to regulation and certification. The interviewee was a manager.</div><div id="Par40" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeItalic">Company E</span> is a global software company that develops both software and hardware solutions for home consumers. The company already has experience running continuous experimentation in their web systems and is starting to run experiments in their hardware solutions. The interviewees were senior data analysts working in experimentation in their embedded systems.</div></div></div><div id="Sec6" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">4 </span>Challenges and Proposed Strategies</h2><div id="Par41" class="Para">This section presents results obtained from the research process. The challenges are grouped in the three different perspectives as discussed in the Experimentation Evolution Model [<cite><a href="#CR4">4</a></cite>]: the technical challenges, the business challenges and the organizational challenges. The technical challenges refer to challenges related to the system architecture, experimentation tooling and development processes. The business challenges refer to challenges faced in the business side, such as evaluation metrics, business models and privacy concerns. The organizational challenges refer to challenges faced by the cultural aspect of the R&amp;D organization.</div><div id="Par42" class="Para">All the strategies identified in this study are used, suggested by companies, or supported by strategies identified in previous literature case studies. The strategies are categorized in three groups: (1) changes in the development process. This refers to how companies organize their development activities. (2) changes in the system’s architecture. Often restrictions in the running experiments comes from limitations in the system’s architecture, that does not support data collection, or does not allow parametrization of features for experiments. (3) changes in how the experiment and organizational data is handled and analyzed. This refers to how the company stores data, comply to data regulations or use data analysis tools. The challenges are not presented in any specific order as they might reflect different challenges the companies are facing.</div><div id="Par43" class="Para">Figure <span class="InternalRef"><a href="#Fig1">1</a></span> represents a summary of the identified challenges and strategies. In Fig. <span class="InternalRef"><a href="#Fig1">1</a></span>, it is possible to see the relation of how each strategy relates to the different challenges, as some of them are part of the strategy of one or more challenge. This figure was obtained using the thematic codes generated in the analysis of the interviews. It maps the identified challenges within their groups with the obtained strategies groups. The rest of this section discusses each challenge individually and presents strategies to overcome them.<div class="Figure" id="Fig1"><div class="MediaObject" id="MO1"><img src="A468350_1_En_20_Fig1_HTML.gif" alt="A468350_1_En_20_Fig1_HTML.gif"/></div><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1.</span><div class="SimplePara">Summary of the challenges and the strategies faced by embedded systems companies adopting continuous experimentation.</div></div></div></div>
</div><div id="Sec7" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.1 </span>Technical Challenges</h3><div id="FPar1" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Lack of over the air (OTA) updates and data collection</div><div id="Par44" class="Para">Continuous experimentation requires over-the-air (OTA) post-deployment data collection and updates. When testing a different hypothesis, the system needs to have the ability to measure the specific behavior under investigation and to update the system with the new variants as well. It is possible to run experiments without OTA, however, several experiments pitfalls can be identified in the first hours and be corrected [<cite><a href="#CR6">6</a></cite>]. Moreover, experiments for optimization are looking in practical significance as low as 1–2% in their metrics [<cite><a href="#CR6">6</a></cite>, <cite><a href="#CR13">13</a></cite>]. If OTA updates and data collection are not available the cost of the experiment and the practical significance level are high and the optimization process might not be worth it.</div></div><div id="FPar2" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par45" class="Para">At the moment of this study, embedded system companies are not looking into experimentation in low level systems, but in computing systems that already support modern operating systems with connectivity and the necessary infrastructure for OTA updates. OTA updates and post-deployment data collection should be part of the functional requirements of the system when designing the hardware. Mobile companies already provide such functionality in their operating systems. Car manufacturers are also introducing continuous delivery of new software to their vehicles in the context of autonomous vehicles (Tesla Motor’s Model S, Volvo Drive Me and the Volvo XC90).</div></div><div id="FPar3" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Lack of experimentation tools that integrate with their existing tooling</div><div id="Par46" class="Para">Continuous experimentation started in web-facing companies. Today several experimentation tools, both commercial and open source, are available on the website and mobile applications domains. However, in the embedded systems domain, companies lack tools that integrate with their development process. Setting up an infrastructure to run experiments from scratch increases the cost of running the first experiments while hindering the benefits.</div></div><div id="FPar4" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par47" class="Para">Several tools available for websites are open source or have open source SDKs. Although not ideal, some of these tools can be modified to support experimentation problems. Experimentation-as-a-Service (EaaS) is a business model that provides a working platform for continuous experimentation. EaaS have the benefit of avoiding the cost and pitfalls of development of an experimentation platform from scratch. EaaS platforms also provide SDKs that can be incorporated in the product [<cite><a href="#CR22">22</a></cite>]. However, the system under experimentation should support data collection so it can be integrated with EaaS tools.</div></div><div id="FPar5" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Expensive testing environments</div><div id="Par48" class="Para">Software-intensive embedded systems are extensively tested before release. One of the challenges faced by embedded systems companies is to include experimentation as part of the verification and validation process. In some cases, such as in the development of a new vehicle, the testing environment is expensive and not all experiment hypotheses are allowed to go to a physical testing platform. This high cost also increases minimum level necessary to reach practical significance and demotivates teams to formulate hypothesis beyond the basic requirements of the system.</div></div><div id="FPar6" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par49" class="Para">The development of experiments in the embedded systems domain require additional steps from the hypothesis to the final user. The development of a feature in embedded systems follows a testing procedure, beginning with integration and going to simulation, test beds, internal deployment until user deployment. The experimentation procedure should follow similar testing procedure, to identify early pitfalls, and even improve the system behavior during each testing phase.</div></div><div id="Par50" class="Para">The practical significance level to implement a new hypothesis increases with the associated costs of such testing procedure. The EDAX model [<cite><a href="#CR17">17</a></cite>] describes how experimentation and automated experimentation is incorporated in this process. Automated experimentation [<cite><a href="#CR18">18</a></cite>] also suggests that it can reduce the experimentation costs and therefore the practical significance level.</div><div id="FPar7" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Experimentation constraints in real-time and safety-critical systems</div><div id="Par51" class="Para">Embedded systems are employed in several real-time and safety-critical systems. These products have subsystems that are constrained to regulations and certification. Experimenting with these systems in the field might not be allowed by regulation or might impact substantially the performance of the system.</div></div><div id="FPar8" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par52" class="Para">Embedded systems companies are starting to run their first experiments. Safety-critical or real-time systems provide additional challenges, as it is subjected to legislation and certification. The initial recommendation in all case study companies is not to run experimentations in these subsystems. However, these safety-critical subsystems can run experiments in the earlier phases prior to the deployment, as discussed in the EDAX model [<cite><a href="#CR17">17</a></cite>].</div></div></div><div id="Sec8" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.2 </span>Business Challenges</h3><div id="FPar9" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Determining good experimentation metrics and metrics validation</div><div id="Par53" class="Para">One of the biggest challenge faced by companies is to determine good business metrics to understand and compare different experiments, and validate that the current metrics are aligned with the company strategy</div></div><div id="FPar10" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par54" class="Para">Web companies traditionally rely on conversion metrics such as Click-Through-Rate in the beginning of their experimentation process. As their experimentation teams and the number of experiments increase the metrics start to become more tailored to the business and stable [<cite><a href="#CR4">4</a></cite>]. Embedded systems companies can have very different and complex metrics, depending on the product. However, team level optimization experiments can use customized metrics. Olsson and Bosch [<cite><a href="#CR14">14</a></cite>] presents a systematic approach to determine metrics and value functions for experiments. This is an iterative process that should be refined with usage and aligned with the business strategies and goals. As the metrics become complex, companies allocate of resources for the evolution and ensuring that the experiment metrics are aligned with the company’s main KPIs.</div></div><div id="FPar11" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Privacy concerns regarding user data</div><div id="Par55" class="Para">Continuous experimentation relies on the collection and analysis of post-deployed software. However, some issues arise when collecting data, such as the legal and contractual issues or user consent and data sharing.</div></div><div id="FPar12" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par56" class="Para">Data sensitivity and the use of data vary largely between different organizations and countries. Data collection should be aligned with the legal requirements for utilization and consent of the users. Data regulations such as the European GDPR (<span class="ExternalRef"><a href="https://www.eugdpr.org/"><span class="RefSource">https://​www.​eugdpr.​org/​</span></a></span>) create restrictions that might imply in technology and process modifications for compliance. Additionally, some ethical questions regarding the experiment must be evaluated, such as: How are participants guaranteed that their data, which was collected for use in the study, will not be used for some other purpose? What data may be published more broadly, and does that introduce any additional risk to the participants? Web companies, besides compliance with regulations also create ethical checklists to ensure that the experiments follow the companies’ policies [<cite><a href="#CR23">23</a></cite>].</div></div><div id="FPar13" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Lack of sharing user data in business-to-business (B2B) solutions</div><div id="Par57" class="Para">Several embedded systems companies operate in a business-to-business domain. In this scenario, there is a difference between user and customer data. Experiments with users might not be possible, they might require deeper involvement between the companies, or there might be a mismatch between the customer and the user value [<cite><a href="#CR1">1</a></cite>].</div></div><div id="FPar14" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par58" class="Para">Ecosystems refers to companies co-opting third parties to build and leverage their products and services in such a way that they have more utility value to their customers [<cite><a href="#CR24">24</a></cite>]. In this sense, companies might agree on implementing and sharing data collected inside the ecosystem. Some mobile operating systems (e.g. iOS and Android) collect data and usage statistics to share with app developers. Although most of its use is connected to crash reports, similar strategies can be used to share user data in business-to-business products.</div></div><div id="FPar15" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Lack of insights obtained from the collected data</div><div id="Par59" class="Para">Companies are continuously collecting data from their deployed software. The collected data is mainly used for troubleshooting purposes. However, little insight is provided by the collected data [<cite><a href="#CR14">14</a></cite>]. In the Experimentation Evolution Model [<cite><a href="#CR4">4</a></cite>], web companies evolve from centralized data science teams to small data science teams presented in each product teams. The interviewed embedded systems companies don’t have data science teams incorporated in the product development.</div></div><div id="FPar16" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par60" class="Para">If the experimentation benefits are not clear, the extra cost of involving data scientists in the product development might be a large step. Different companies started to provided experimentation and data analysis services. Experimentation tools usually incorporate basic statistical analysis, such as statistical significance testing, power analysis, A/A tests and more. Using experimentation and data analysis services to generate basic insights can be used as a short-term solution. Once the benefits of experimentation are clear to the company, investments such as integrating data scientists in the product development or acquiring a complex tool are easier to justify.</div></div><div id="FPar17" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Long release cycles</div><div id="Par61" class="Para">Traditionally, embedded systems have a long software release cycle based on upfront defined requirements. Sometimes the software is deployed only once and last for several years [<cite><a href="#CR1">1</a></cite>, <cite><a href="#CR15">15</a></cite>]. This happens due to several reasons, from both the organizational (structure and decision-making) and business (engineering effort in every cycle, requirements definition and products updates) to the technical perspective (architecture, functionalities available and support for over-the-air updates).</div></div><div id="FPar18" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par62" class="Para">From the organizational and business perspective, continuous experimentation aligns with the organizational transition to agile methodologies and the Lean Startup methodology [<cite><a href="#CR12">12</a></cite>]. Continuous experimentation makes use of extreme programming practices such as continuous integration, delivery and deployment to deliver experiments and new software aligned with customer behavior. The Stairway to Heaven [<cite><a href="#CR7">7</a></cite>] conceptual model helps companies to evolve their practices towards continuous deployment of software.</div></div></div><div id="Sec9" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.3 </span>Organizational Challenges</h3><div id="FPar19" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Managing multiple stakeholders in the experiment design</div><div id="Par63" class="Para">One of the challenges embedded systems companies face is the involvement of multiple stakeholders in an experimental design. Experimentation in embedded systems requires that the involved stakeholders understand the implications of continuous practices in their systems.</div></div><div id="FPar20" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par64" class="Para">Embedded systems require the interaction with multiple stakeholders, such as software developers, systems architects, electrical and mechanical engineers, suppliers and subcontractors. Continuous experimentation requires that these stakeholders are aware of the implications in the system design. To overcome some of these challenges, it is prosed a decoupling of the application and the underlying software and also a decoupling in time (software is not integrated at the manufacturing time) [<cite><a href="#CR15">15</a></cite>]. Additionally, if the interaction of the stakeholders happens in a business ecosystems perspective the experiment can be designed to benefit multiple parts [<cite><a href="#CR24">24</a></cite>].</div></div><div id="FPar21" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Highest Paid Person Opinion - HiPPO</div><div id="Par65" class="Para">Some companies are organized in vertical structures, where lower rank developers have fewer possibilities to influence and address customer’s needs. Several requirements and architecture specifications are based and determined by higher paid ranks inside the company.</div></div><div id="FPar22" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par66" class="Para">This challenge is persistent in several domains and it is not restricted to the embedded systems industries. This challenge is discussed extensively in [<cite><a href="#CR6">6</a></cite>] among other publications. The traditional adopted strategy is to run the first experiments. Usually, experiments continuously disprove beliefs and opinions adopted by the higher paid ranks [<cite><a href="#CR6">6</a></cite>]. However, this requires changes in the organizational and cultural aspect of the company.</div></div><div id="FPar23" class="FormalPara FormalParaRenderingStyle3"><div class="Heading">Tuning experiments is repetitive and requires highly qualified engineers</div><div id="Par67" class="Para">One of the interviewed companies runs experiments for parameter optimization. The experiments rely on the system response instead of the customer response. However, running these experiments for tuning and optimization is a repetitive task that consumes R&amp;D time and requires highly qualified engineers to perform them.</div></div><div id="FPar24" class="FormalPara FormalParaRenderingStyle1"><div class="Heading">Strategies:</div><div id="Par68" class="Para">Existing algorithms in search-based optimization, reinforcement learning and others artificial intelligence algorithms support this kind of optimization strategies. However, both the complexity of these algorithms as well as the introduced technical debt in the existing systems [<cite><a href="#CR25">25</a></cite>] prevent embedded systems companies to use such strategies. Experimentation-as-a-Service solutions allow companies to test Machine Learning algorithms in their system for optimization purposes. Although still in early phases, automated experimentation [<cite><a href="#CR18">18</a></cite>] solutions can help companies to optimize their systems through field experiments.</div></div></div></div><div id="Sec10" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">5 </span>Validity Threats</h2><div id="Par69" class="Para">The first threat to the validity of this study refers to the scope of the literature review. The search query was applied to the Scopus indexing library. Both the choice of the search string and the indexing library could miss other research work that can contribute to the literature review. To mitigate this threat the authors performed a backward and forward snowballing [<cite><a href="#CR20">20</a></cite>] process. The snowballing process allowed the authors to identify other cited work in the same area that was not identified by the search query.</div><div id="Par70" class="Para">An external validity to this is study is the generalization of the challenges to the entire population of embedded systems companies. To mitigate this threat, the authors sample companies producing different products in embedded systems. The authors sampled contacted multiple companies explaining the research goal, and selected only companies that are adopting/running controlled experiments in their development process were included. During the data analysis part, we reviewed all challenges only challenges that had correspondence in more than one company or that could be triangulated with the literature review were included. Challenges that could not be triangulated with other source, and that could be specific to current situation of the company, were not included in this study.</div><div id="Par71" class="Para">The companies that participated in this study are adopting their first steps towards continuous experimentation and are running their first experiments or trying to scale experimentation practices from a few development teams to the organization. Therefore, most of the presented challenges are faced in these first steps and cannot be generalized to companies or teams that are running experimentation at scale. As the companies evolve their experimentation practices, new challenges will arise from all three perspectives.</div></div><div id="Sec11" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">6 </span>Conclusion</h2><div id="Par72" class="Para">This paper addresses the question of how embedded systems companies can adopt continuous experimentation in their software development process. This question can be divided in two parts: first, the identification of problems and challenges that limit the adoption of continuous experimentation, and second selected strategies adopted by companies to overcome these challenges.</div><div id="Par73" class="Para">This paper identified twelve key challenges faced by embedded systems and them grouped in three perspectives, the business, the technical and the organizational. The challenges are also presented with suggested strategies to overcome them. The set of strategies can be grouped in three categories, changes that need to take place in how the company handles and analyze the post-deployment collected data, changes in the company development process and changes in the product architecture. The relation between the different strategies and the challenges is seen in Fig. <span class="InternalRef"><a href="#Fig1">1</a></span>. The paper used a combination of literature review and a multiple company case study to provide a stronger empirical evidence.</div><div id="Par74" class="Para">Further research is needed to understanding how the system can be architected to support continuous experimentation as a first-class citizen in the development process while still guaranteeing safety and real-time requirements as well as intermittent connectivity. Additionally, continuous experimentation changes how the development process takes place, as it emphasizes in an outcome-driven development and this scenario might lead to impactful organizational changes. For future works, the authors are investigating where is the perceived highest return on investment that companies see and plan to invest to overcome the identified challenges and further support of continuous experimentation in their products.</div></div><div class="Acknowledgments"><div class="Heading">Acknowledgments</div><div class="SimplePara">This work was partially supported by the Wallenberg Autonomous Systems and Software Program (WASP) and the Software Center.</div></div><div class="License LicenseSubType-cc-by"><a href="https://creativecommons.org/licenses/by/4.0"><img src="cc-by.png" alt="Creative Commons"/></a><div class="SimplePara">Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this book are included in the book's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the book's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</div></div><div class="Bibliography" id="Bib1"><div class="Heading">References</div><div class="BibliographyWrapper"><div class="Citation"><div class="CitationNumber">1.</div><div class="CitationContent" id="CR1">Lindgren, E., Münch, J.: Raising the odds of success: the current state of experimentation in product development. Inf. Softw. Technol. <span class="EmphasisTypeBold">77</span>, 80–91 (2016)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1016/j.infsof.2016.04.008"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">2.</div><div class="CitationContent" id="CR2">Eliasson, U., Heldal, R., Knauss, E., Pelliccione, P.: The need of complementing plan-driven requirements engineering with emerging communication: experiences from Volvo Car Group. In: Proceedings of 2015 IEEE 23rd International Requirements Engineering Conference RE 2015, pp. 372–381 (2015)</div></div><div class="Citation"><div class="CitationNumber">3.</div><div class="CitationContent" id="CR3">Olsson, H.H., Bosch, J.: From opinions to data-driven software R&amp;D: a multi-case study on how to close the ‘open loop’ problem. In: Proceedings of 40th Euromicro Conference Series on Software Engineering and Advanced Applications SEAA 2014, pp. 9–16 (2014)</div></div><div class="Citation"><div class="CitationNumber">4.</div><div class="CitationContent" id="CR4">Fabijan, A., Dmitriev, P., Olsson, H.H., Bosch, J.: The evolution of continuous experimentation in software product development. In: Proceedings of the 39th International Conference on Software Engineering ICSE 2017 (2017)</div></div><div class="Citation"><div class="CitationNumber">5.</div><div class="CitationContent" id="CR5">Tang, D., Agarwal, A., O’Brien, D., Meyer, M.: Overlapping experiment infrastructure. In: Proceedings of the 16th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining-KDD 2010, p. 17 (2010)</div></div><div class="Citation"><div class="CitationNumber">6.</div><div class="CitationContent" id="CR6">Kohavi, R., Longbotham, R., Sommerfield, D., Henne, R.M.: Controlled experiments on the web: survey and practical guide. Data Min. Knowl. Discov. <span class="EmphasisTypeBold">18</span>(1), 140–181 (2009)<span class="Occurrences"><span class="Occurrence OccurrenceAMSID"><a href="http://www.ams.org/mathscinet-getitem?mr=2469594"><span><span>MathSciNet</span></span></a></span><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/s10618-008-0114-1"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">7.</div><div class="CitationContent" id="CR7">Olsson, H.H., Bosch, J.: Climbing the “Stairway to Heaven”: evolving from agile development to continuous deployment of software. In: Bosch, J. (ed.) Continuous Software Engineering, pp. 15–27. Springer, Cham (2014). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-319-11283-1_2"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-319-11283-1_​2</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-319-11283-1_2"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">8.</div><div class="CitationContent" id="CR8">Bosch, J.: Building products as innovation experiment systems. In: Cusumano, M.A., Iyer, B., Venkatraman, N. (eds.) ICSOB 2012. LNBIP, vol. 114, pp. 27–39. Springer, Heidelberg (2012). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-642-30746-1_3"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-642-30746-1_​3</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-642-30746-1_3"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">9.</div><div class="CitationContent" id="CR9">Olsson, H.H., Bosch, J.: The HYPEX model: from opinions to data-driven software development. In: Bosch, J. (ed.) Continuous Software Engineering, pp. 1–226. Springer, Cham (2014). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-319-11283-1_13"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-319-11283-1_​13</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-319-11283-1_13"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">10.</div><div class="CitationContent" id="CR10">Fabijan, A., Olsson, H.H., Bosch, J.: The lack of sharing of customer data in large software organizations: challenges and implications. In: Sharp, H., Hall, T. (eds.) XP 2016. LNBIP, vol. 251, pp. 39–52. Springer, Cham (2016). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-319-33515-5_4"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-319-33515-5_​4</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-319-33515-5_4"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">11.</div><div class="CitationContent" id="CR11">Fagerholm, F., Sanchez Guinea, A., Mäenpää, H., Münch, J.: The RIGHT model for continuous experimentation. J. Syst. Softw. <span class="EmphasisTypeBold">123</span>, 292–305 (2017)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1016/j.jss.2016.03.034"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">12.</div><div class="CitationContent" id="CR12">Ries, E.: The Lean Startup: How Today’s Entrepreneurs Use Continuous Innovation to Create Radically Successful Businesses, 1st edn. Crown Publishing Group, New York (2011)</div></div><div class="Citation"><div class="CitationNumber">13.</div><div class="CitationContent" id="CR13">Kohavi, R., Deng, A., Longbotham, R., Xu, Y.: Seven rules of thumb for web site experimenters. In: Proceedings of the 20th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining<span class="EmphasisTypeItalic">-</span>KDD 2014, pp. 1857–1866 (2014)</div></div><div class="Citation"><div class="CitationNumber">14.</div><div class="CitationContent" id="CR14">Olsson, H.H., Bosch, J.: So much data ; so little value : a multi-case study on improving the impact of data-driven development practices. In: Proceedings of the Ibero American Conference on Software Engineering (ClbSE), 22nd–23rd May, Buenos Aires, Argentina (2017)</div></div><div class="Citation"><div class="CitationNumber">15.</div><div class="CitationContent" id="CR15">Bosch, J., Eklund, U.: Eternal embedded software: towards innovation experiment systems. In: Margaria, T., Steffen, B. (eds.) ISoLA 2012. LNCS, vol. 7609, pp. 19–31. Springer, Heidelberg (2012). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-642-34026-0_3"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-642-34026-0_​3</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-642-34026-0_3"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">16.</div><div class="CitationContent" id="CR16">Giaimo, F., Berger, C.: Design criteria to architect continuous experimentation for self-driving vehicles. In: 2017 IEEE International Conference on Software Architecture (ICSA), pp. 203–210 (2017)</div></div><div class="Citation"><div class="CitationNumber">17.</div><div class="CitationContent" id="CR17">Bosch, J., Olsson, H.H.: Data-driven continuous evolution of smart systems. In: Proceedings of the 11th International Workshop on Software Engineering for Adaptive and Self-Managing Systems-SEAMS 2016, pp. 28–34 (2016)</div></div><div class="Citation"><div class="CitationNumber">18.</div><div class="CitationContent" id="CR18">Mattos, D.I., Bosch, J., Olsson, H.H.: Your system gets better every day you use it: towards automated continuous experimentation. In: Proceedings of the 43th Euromicro Conference on Software Engineering and Advanced Applications (SEAA) (2017)</div></div><div class="Citation"><div class="CitationNumber">19.</div><div class="CitationContent" id="CR19">Mattos, D.I., Bosch, J., Holmström Olsson, H.: More for less: automated experimentation in software-intensive systems. In: Felderer, M., Méndez Fernández, D., Turhan, B., Kalinowski, M., Sarro, F., Winkler, D. (eds.) PROFES 2017. LNCS, vol. 10611, pp. 146–161. Springer, Cham (2017). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-319-69926-4_12"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-319-69926-4_​12</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-319-69926-4_12"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">20.</div><div class="CitationContent" id="CR20">Wohlin, C., Runeson, P., Höst, M., Ohlsson, M.C., Regnell, B., Wesslén, A.: Experimentation in Software Engineering, vol. 1. Springer, Heidelberg (2012). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-642-29044-2"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-642-29044-2</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-642-29044-2"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">21.</div><div class="CitationContent" id="CR21">Runeson, P., Höst, M.: Guidelines for conducting and reporting case study research in software engineering. Empir. Softw. Eng. <span class="EmphasisTypeBold">14</span>(2), 131–164 (2009)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/s10664-008-9102-8"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">22.</div><div class="CitationContent" id="CR22">Optimizely, “Optimizely.” <span class="ExternalRef"><a href="https://www.optimizely.com/"><span class="RefSource">https://​www.​optimizely.​com/​</span></a></span>. Accessed 28 June 2017</div></div><div class="Citation"><div class="CitationNumber">23.</div><div class="CitationContent" id="CR23">Zhang, B.: Privacy Concerns in Online Recommender Systems: Influences of Control and User Data Input, pp. 159–173 (2014)</div></div><div class="Citation"><div class="CitationNumber">24.</div><div class="CitationContent" id="CR24">Holmström Olsson, H., Bosch, J.: From ad hoc to strategic ecosystem management: the Three-Layer Ecosystem Strategy Model? (TeLESM). J. Softw. Evol. Process <span class="EmphasisTypeBold">29</span>, e1876 (2017)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1002/smr.1876"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">25.</div><div class="CitationContent" id="CR25">Sculley, D., Holt, G., Golovin, D., Davydov, E., Phillips, T., Ebner, D., Chaudhary, V., Young, M., Dennison, D.: Hidden Technical debt in machine learning systems. In: NIPS, pp. 2494–2502 (2015)</div></div></div></div></div></body></html>
