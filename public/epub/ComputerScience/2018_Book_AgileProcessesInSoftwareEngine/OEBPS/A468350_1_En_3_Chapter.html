<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><title>Combining STPA and BDD for Safety Analysis and Verification in Agile Development: A Controlled Experiment</title><link href="springer_epub.css" type="text/css" rel="styleSheet"/></head><body><div class="ChapterContextInformation"><div class="ContextInformation" id="Chap3"><div class="ChapterCopyright">© The Author(s) 2018</div><span class="ContextInformationAuthorEditorNames"><span class="Editor"><span class="EditorName">Juan Garbajosa</span>, </span><span class="Editor"><span class="EditorName">Xiaofeng Wang</span> and </span><span class="Editor"><span class="EditorName">Ademar Aguiar</span></span><span class="CollaboratorDesignation"> (eds.)</span></span><span class="ContextInformationBookTitles"><span class="BookTitle" xml:lang="en">Agile Processes in Software Engineering and Extreme Programming</span></span><span class="ContextInformationSeries"><span class="SeriesTitle" xml:lang="en">Lecture Notes in Business Information Processing</span><span class="ContextInformationVolumeNumber">314</span></span><span class="ChapterDOI"><a href="A468350_1_En_3_Chapter.html">https://doi.org/10.1007/978-3-319-91602-6_3</a></span></div></div><!--Begin Abstract--><div class="MainTitleSection"><h1 class="ChapterTitle" xml:lang="en">Combining STPA and BDD for Safety Analysis and Verification in Agile Development: A Controlled Experiment</h1></div><div class="AuthorGroup"><div class="AuthorNames"><span class="Author"><span class="AuthorName">Yang Wang</span><sup>1 <a href="#ContactOfAuthor1"><span class="ContactIcon"> </span></a></sup> and </span><span class="Author"><span class="AuthorName">Stefan Wagner</span><sup>1 <a href="#ContactOfAuthor2"><span class="ContactIcon"> </span></a></sup></span></div><div class="Affiliations"><div class="Affiliation" id="Aff9"><span class="AffiliationNumber">(1)</span><div class="AffiliationText">University of Stuttgart, Stuttgart, Germany</div></div><div class="ClearBoth"> </div></div><div class="Contacts"><div class="Contact" id="ContactOfAuthor1"><div class="ContactIcon"> </div><div class="ContactAuthorLine"><span class="AuthorName">Yang Wang</span> (Corresponding author)</div><div class="ContactAdditionalLine"><span class="ContactType">Email: </span><a href="mailto:yang.wang@informatik.uni-stuttgart.de" class="Email">yang.wang@informatik.uni-stuttgart.de</a></div></div><div class="Contact" id="ContactOfAuthor2"><div class="ContactIcon"> </div><div class="ContactAuthorLine"><span class="AuthorName">Stefan Wagner</span></div><div class="ContactAdditionalLine"><span class="ContactType">Email: </span><a href="mailto:stefan.wagner@informatik.uni-stuttgart.de" class="Email">stefan.wagner@informatik.uni-stuttgart.de</a></div></div></div></div><div class="Abstract" id="Abs1" xml:lang="en"><div class="Heading">Abstract</div><div id="Par1" class="Para"><span class="EmphasisTypeItalic">Context:</span> Agile development is in widespread use, even in safety-critical domains. <span class="EmphasisTypeItalic">Motivation:</span> However, there is a lack of an appropriate safety analysis and verification method in agile development. <span class="EmphasisTypeItalic">Objective:</span> In this paper, we investigate the use of Behavior Driven Development (BDD) instead of standard User Acceptance Testing (UAT) for safety verification with System-Theoretic Process Analysis (STPA) for safety analysis in agile development. <span class="EmphasisTypeItalic">Method:</span> We evaluate the effect of this combination in a controlled experiment with 44 students in terms of productivity, test thoroughness, fault detection effectiveness and communication effectiveness. <span class="EmphasisTypeItalic">Results:</span> The results show that BDD is more effective for safety verification regarding the impact on communication effectiveness than standard UAT, whereas productivity, test thoroughness and fault detection effectiveness show no statistically significant difference in our controlled experiment. <span class="EmphasisTypeItalic">Conclusion:</span> The combination of BDD and STPA seems promising with an enhancement on communication, but its impact needs more research.</div></div><!--End Abstract--><div class="Fulltext"><div id="Sec1" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">1 </span>Introduction</h2><div id="Par2" class="Para">Agile practices have been widely used in software industries to develop systems on time and within budget with improved software quality and customer satisfaction [<cite><a href="#CR1">1</a></cite>]. The success of agile development has led to a proposed expansion to include safety-critical systems (SCS) [<cite><a href="#CR2">2</a></cite>]. However, to develop SCS in an agile way, a significant challenge exists in the execution of safety analysis and verification [<cite><a href="#CR3">3</a></cite>]. The traditional safety analysis and verification techniques, such as failure mode effect analysis (FMEA) and fault tree analysis (FTA) are difficult to apply within agile development. They need a detailed and stable architecture [<cite><a href="#CR4">4</a></cite>].</div><div id="Par3" class="Para">In 2016, we proposed to use System-Theoretic Process Analysis (STPA) [<cite><a href="#CR6">6</a></cite>] in agile development for SCS [<cite><a href="#CR5">5</a></cite>]. First, STPA can be started without a detailed and stable architecture. It can guide the design. In agile development, a safety analyst starts with performing STPA on a high-level architecture and derives the relevant safety requirements for further design. Second, Leveson developed STPA based on the systems theoretic accident modeling and processes (STAMP) causality model, which considers safety problems based on system theory rather than reliability theory. In today’s complex cyber-physical systems, accidents are rarely caused by single component or function failures but rather by component interactions, cognitively complex human decision-making errors and social, organizational, and management factors [<cite><a href="#CR6">6</a></cite>]. System theory can address this.</div><div id="Par4" class="Para">The safety requirements derived from STPA need verification. However, there is no congruent safety verification in agile development. Most agile practitioners mix unit test, integration test, field test and user acceptance testing (UAT) to verify safety requirements [<cite><a href="#CR2">2</a></cite>]. In 2016, we proposed using model checking combined with STPA in a Scrum development process [<cite><a href="#CR7">7</a></cite>]. However, using model checking, a suitable model is necessary but usually not available in agile development. In addition, the formal specification increases the difficulties of communication, which should not be neglected when developing SCS [<cite><a href="#CR8">8</a></cite>]. BDD, as an agile technique, is an evolution of test driven development (TDD) and acceptance test driven development (ATDD). The developers repeat coding cycles interleaved with testing. TDD starts with writing a unit test, while ATDD focuses on capturing user stories by implementing automated tests. BDD relies on testing system behavior in scenarios by implementing a template: Given[Context], When[Event], Then[Outcome] [<cite><a href="#CR31">31</a></cite>]. The context describes pre-conditions or system states, the event describes a trigger event, and the outcome is an expected or unexpected system behavior. It could go further into low-level BDD<a href="#Fn1" id="Fn1_source"><sup>1</sup></a>. Yet, it has not been used to verify safety requirements. Leveson said [<cite><a href="#CR6">6</a></cite>]: “<span class="EmphasisTypeItalic">Accidents are the result of a complex process that results in system behavior violating the safety constraints.</span>” Hence, in agile development, we need safety verification to: (1) be able to guide design at an early stage, (2) strengthen communication and (3) focus on verifying system behavior. Thus, we believe that BDD might be suitable for safety verification with STPA for safety analysis in agile development.</div><div id="Par6" class="Para ParaOneEmphasisChild">
                <span class="EmphasisTypeBold">Contributions</span>
              </div><div id="Par7" class="Para">We propose a possible way to use BDD with STPA for safety verification in agile development. We investigate its effects regarding productivity, test thoroughness, fault detection effectiveness and communication effectiveness by conducting a controlled experiment with the limitation that we execute BDD only in a test-last way. The results show that BDD is able to verify safety requirements based on system theory, and is more effective than UAT regarding communication for safety verification.</div></div><div id="Sec2" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">2 </span>Related Work</h2><div id="Par8" class="Para">Modern agile development processes for developing safety-critical systems (SCS) advocate a hybrid mode through alignment with standards like IEC 61508, ISO 26262 and DO-178. There have been many considerable successes [<cite><a href="#CR9">9</a></cite>–<cite><a href="#CR11">11</a></cite>]. However, a lack of integrated safety analysis and verification to face the changing architecture through each short iteration is a challenge for using such standards. In 2016, we proposed to use STPA in a Scrum development process [<cite><a href="#CR5">5</a></cite>]. It showed a good capability to ensure agility and safety in a student project [<cite><a href="#CR12">12</a></cite>]. However, we verified the safety requirements only at the end of each sprint by executing UAT together with TDD in development. A lack of integrated safety verification causes some challenges, such as poor verification and communication. The previous research regarding safety verification in agile development suggested using formal methods [<cite><a href="#CR13">13</a></cite>, <cite><a href="#CR14">14</a></cite>]. However, they need models and make intuitive communication harder [<cite><a href="#CR7">7</a></cite>]. In addition, they have not considered specific safety analysis techniques.</div><div id="Par9" class="Para">Hence, we propose using BDD to verify safety requirements. BDD is specifically for concentrating on behavior testing [<cite><a href="#CR15">15</a></cite>]. It allows automated testing against multiple artifacts throughout the iterative development process [<cite><a href="#CR17">17</a></cite>]. Moreover, it bridges the gap between natural language-based business rules and code language [<cite><a href="#CR18">18</a></cite>]. Okubo et al. [<cite><a href="#CR19">19</a></cite>] mentioned the possibilities of using BDD for security and privacy acceptance criteria. They define the acceptance criteria by creating a threat and countermeasure graph to write attack scenarios. They verify the satisfication of security requirements by testing the countermeasures, to see whether they can make the attack scenarios or unsecure scenarios fail. Lai et al. [<cite><a href="#CR20">20</a></cite>] combined BDD with iterative and incremental development specifically for security requirements evaluation. They defined the behavioral scenarios by using use case diagram and misuse case diagram. STPA encompasses determining safe or unsafe scenarios. We aim to use BDD verifying these scenarios.</div><div id="Par10" class="Para">To investigate the effect of using BDD for safety verification, we design a controlled experiment referring to a set of TDD experiments. Erdogmus et al. [<cite><a href="#CR23">23</a></cite>] conducted an experiment with undergraduate students regarding programmer productivity and external quality in an incremental development process. For safety verification in agile development, a high productivity of safety test cases promotes high safety. Madeyski [<cite><a href="#CR26">26</a></cite>] conducted an experiment comparing “test-first” and “test-last” programming practices with regard to test thoroughness and fault detection effectiveness of unit tests. BDD for safety verification covers also low-level tests. Thus, we decided to investigate productivity, test thoroughness and fault detection capability in this experiment. [<cite><a href="#CR21">21</a></cite>, <cite><a href="#CR22">22</a></cite>, <cite><a href="#CR28">28</a></cite>–<cite><a href="#CR30">30</a></cite>] provided evidence of using these three measures. In addition, George and Williams [<cite><a href="#CR29">29</a></cite>] focused on the understandability of TDD from the developer’s viewpoint. Using BDD for safety verification, we notice the importance of communication between developers and business analysts. We investigate understandability in the measure of communication effectiveness.</div></div><div id="Sec3" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">3 </span>STPA Integrated BDD for Safety Analysis and Verification (STPA-BDD)</h2><div id="Par11" class="Para">In this article, we propose STPA-BDD. We mainly focus on safety verification. As we can see in Fig. <span class="InternalRef"><a href="#Fig1">1</a></span>, we have two main parts: STPA safety analysis and BDD safety verification. A safety analyst<a href="#Fn2" id="Fn2_source"><sup>2</sup></a> (QA) starts performing STPA safety analysis with a sufficient amount of code<a href="#Fn3" id="Fn3_source"><sup>3</sup></a>. STPA is executed by firstly identifying potentially hazardous control actions, and secondly determining how unsafe control actions (UCAs) could occur. STPA derives the safety requirements, which constraint the UCAs, as well as system behaviors. Additionally, it explores the causal factors in scenarios for each UCA. The output from the safety analyst (QA) is an STPA safety report with system description, control structure, accidents, hazards, UCAs, corresponding safety requirements, process variables and algorithms.<div class="Figure" id="Fig1"><div class="MediaObject" id="MO1"><img src="A468350_1_En_3_Fig1_HTML.gif" alt="A468350_1_En_3_Fig1_HTML.gif"/></div><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 1.</span><div class="SimplePara">STPA-BDD concept</div></div></div></div>
</div><div id="Par14" class="Para">In BDD safety verification, to generate and test scenarios, the UCAs (in STPA step 1), process variables and algorithms (in STPA step 2) from the STPA safety report are needed. We write other data into “others”. BDD safety verification has two steps: In step 1, the business analyst, the safety analyst (QA) and the developer establish a “3 Amigos Meeting” to generate test scenarios. In a BDD test scenario<a href="#Fn4" id="Fn4_source"><sup>4</sup></a>, we write the possible trigger event for the UCA in <span class="EmphasisTypeBold">When [Event]</span>. The other process variables and algorithms are arranged in <span class="EmphasisTypeBold">Given [Context]</span>. <span class="EmphasisTypeBold">Then [Outcome]</span> presents the expected behavior - a safe control action. In Fig. <span class="InternalRef"><a href="#Fig2">2</a></span>(a), we present an example. The safety analyst (QA) has provided a UCA as <span class="EmphasisTypeItalic">During auto-parking, the autonomous vehicle does not stop immediately when there is an obstacle upfront.</span> One of the process variables with relevant algorithms detects the forward distance by using an ultrasonic sensor. The developer considers a possible trigger as the ultrasonic sensor provides the wrong feedback. Thus, a BDD test scenario should test if <span class="EmphasisTypeItalic">the ultrasonic sensor provides the feedback that the forward distance</span> <span class="InlineEquation" id="IEq1"><img src="A468350_1_En_3_Chapter_IEq1.gif" alt="$$&lt;=$$"/></span> <span class="EmphasisTypeItalic">threshold (means there is an obstacle upfront)</span> and whether the vehicle stops. They write this after <span class="EmphasisTypeBold">When</span>. The context could be <span class="EmphasisTypeItalic">the autonomous vehicle is auto-parking.</span> We write them after <span class="EmphasisTypeBold">Given</span>. <span class="EmphasisTypeBold">Then</span> constraints the safe control action as <span class="EmphasisTypeItalic">the autonomous vehicle stops immediately</span>. More possible triggers are expected to be generated after <span class="EmphasisTypeBold">When</span> to test them. In step 2, after the three amigos discuss and determine the test scenarios, the developer starts generating them into test cases, as shown in Fig. <span class="InternalRef"><a href="#Fig2">2</a></span>(b). BDD test cases use annotations such as <span class="EmphasisTypeBold">@Given</span>, <span class="EmphasisTypeBold">@When</span>, and <span class="EmphasisTypeBold">@Then</span> to connect the aforementioned test scenarios with real code. The developer produces code to fulfill each annotation. We can identify unsafe scenarios when the test cases fail. We correct the trigger event to pass the test cases to satisfy the safety requirement.<div class="Figure" id="Fig2"><div class="MediaObject" id="MO2"><img src="A468350_1_En_3_Fig2_HTML.gif" alt="A468350_1_En_3_Fig2_HTML.gif"/></div><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 2.</span><div class="SimplePara">BDD safety verification example</div></div></div></div>
</div></div><div id="Sec4" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">4 </span>Experiment Design (We follow the guideline by Wohlin et al. [<cite><a href="#CR32">32</a></cite>].)</h2><div id="Sec5" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.1 </span>Goal</h3><div id="Par16" class="Para"><span class="EmphasisTypeBold">Analyze</span> BDD<a href="#Fn5" id="Fn5_source"><sup>5</sup></a> and UAT<a href="#Fn6" id="Fn6_source"><sup>6</sup></a> for safety verification.</div><div id="Par19" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeBold">For the purpose of</span> comparing their effect.</div><div id="Par20" class="Para"><span class="EmphasisTypeBold">With respect to</span> <span class="EmphasisTypeItalic">productivity</span> by measuring the number of implemented (tested) user stories per minute; <span class="EmphasisTypeItalic">test thoroughness</span> by measuring line coverage; <span class="EmphasisTypeItalic">fault detection effectiveness</span> by measuring a mutation score indicator; <span class="EmphasisTypeItalic">communication effectiveness</span> by conducting a post-questionnaire.</div><div id="Par21" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeBold">From the point of view</span> of the developers and business analysts.</div><div id="Par22" class="Para ParaOneEmphasisChild"><span class="EmphasisTypeBold">In the context of</span> B.Sc students majoring in software engineering or other related majors executing acceptance testing.</div></div><div id="Sec6" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.2 </span>Context</h3><div id="Par23" class="Para"><span class="EmphasisTypeItalic">Participants</span>: The experiment ran off-line in a laboratory setting in an “Introduction to Software Engineering” course at the University of Stuttgart. Since the course includes teaching BDD and UAT technology, the students are suitable subjects for our experiment. We arrange them based on Java programming experiences (not randomly). According to a pre-questionnaire (see footnote 13), 88.6% of the students are majoring in software engineering. We conclude from Table <span class="InternalRef"><a href="#Tab1">1</a></span> that they have attended relevant lectures and handled practical tasks relating to Java programming, acceptance testing, SCS (with a median value &gt;= 3 on a scale from 1 to 5). The agile techniques show less competency (with a median value of 2 on a scale from 1 to 5). We provide a 1-to-1 training, which lasts 44 h overall, to reduce the weaknesses.</div><div id="Par24" class="Para"><span class="EmphasisTypeItalic">Development environment</span>: We use a simplified Java code with mutants from a Lego Mindstorms based Autonomous Parking System (APS) and Crossroad Stop and Go System (CSGS). These two systems are comparable by lines of code and number of functional modules (see footnote 13). To ease writing test cases, we use a lejo TDD wrapper, Testable Lejos<a href="#Fn7" id="Fn7_source"><sup>7</sup></a> to remove deep dependencies to the embedded environment. The BDD groups (Group A1 and Group A2) operate in an Eclipse IDE together with a JBehave plug-in (based on JUnit)<a href="#Fn8" id="Fn8_source"><sup>8</sup></a>. We use Eclipse log files and JUnit test reports for calculating the number of implemented (tested) user stories. Finally, we use PIT Mutation Testing<a href="#Fn9" id="Fn9_source"><sup>9</sup></a> to assess line coverage and a mutation score indicator. The UAT groups (Group B1 and Group B2) write the test cases in Microsoft Word.<div id="Tab1" class="Table"><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 1.</span><div class="SimplePara">Medians of the student’s background</div></div></div><table border="1"><colgroup><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/></colgroup><thead><tr class="header"><th align="left"><div class="SimplePara">Area</div></th><th align="left"><div class="SimplePara">Group A1</div></th><th align="left"><div class="SimplePara">Group A2</div></th><th align="left"><div class="SimplePara">Group B1</div></th><th align="left"><div class="SimplePara">Group B2</div></th></tr></thead><tbody><tr class="noclass"><td align="left"><div class="SimplePara">Java programming</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">3</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Acceptance testing</div></td><td align="left"><div class="SimplePara">4</div></td><td align="left"><div class="SimplePara">5</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">3</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Safety-critical systems</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">4</div></td><td align="left"><div class="SimplePara">4</div></td><td align="left"><div class="SimplePara">4</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Agile techniques</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">3</div></td><td align="left"><div class="SimplePara">2</div></td></tr></tbody></table><div class="TableFooter"><div class="SimplePara">Note: The values range from “1” (little experience) to “5” (experienced). Group A1 and Group A2 use BDD, while Group B1 and Group B2 use UAT.</div></div></div>
</div></div><div id="Sec7" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.3 </span>Hypotheses</h3><div id="Par28" class="Para">We formulate the null hypotheses as:</div><div id="Par29" class="Para"><span class="InlineEquation" id="IEq2"><img src="A468350_1_En_3_Chapter_IEq2.gif" alt="$$H_0$$"/></span> <span class="InlineEquation" id="IEq3"><img src="A468350_1_En_3_Chapter_IEq3.gif" alt="$$_{PROD}$$"/></span>: There is no difference in productivity between BDD and UAT.</div><div id="Par30" class="Para"><span class="InlineEquation" id="IEq4"><img src="A468350_1_En_3_Chapter_IEq4.gif" alt="$$H_0$$"/></span> <span class="InlineEquation" id="IEq5"><img src="A468350_1_En_3_Chapter_IEq5.gif" alt="$$_{THOR}$$"/></span>: There is no difference in test thoroughness between BDD and UAT.</div><div id="Par31" class="Para"><span class="InlineEquation" id="IEq6"><img src="A468350_1_En_3_Chapter_IEq6.gif" alt="$$H_0$$"/></span> <span class="InlineEquation" id="IEq7"><img src="A468350_1_En_3_Chapter_IEq7.gif" alt="$$_{FAUL}$$"/></span>: There is no difference in fault detection effectiveness between BDD and UAT.</div><div id="Par32" class="Para"><span class="InlineEquation" id="IEq8"><img src="A468350_1_En_3_Chapter_IEq8.gif" alt="$$H_0$$"/></span> <span class="InlineEquation" id="IEq9"><img src="A468350_1_En_3_Chapter_IEq9.gif" alt="$$_{COME}$$"/></span>: There is no difference in communication effectiveness between BDD and UAT.</div><div id="Par33" class="Para">The alternative hypotheses are:</div><div id="Par34" class="Para"><span class="InlineEquation" id="IEq10"><img src="A468350_1_En_3_Chapter_IEq10.gif" alt="$$H_1$$"/></span> <span class="InlineEquation" id="IEq11"><img src="A468350_1_En_3_Chapter_IEq11.gif" alt="$$_{PROD}$$"/></span>: BDD is more productive than UAT when producing safety test cases.</div><div id="Par35" class="Para"><span class="InlineEquation" id="IEq12"><img src="A468350_1_En_3_Chapter_IEq12.gif" alt="$$H_1$$"/></span> <span class="InlineEquation" id="IEq13"><img src="A468350_1_En_3_Chapter_IEq13.gif" alt="$$_{THOR}$$"/></span>: BDD yields better test thoroughness than UAT.</div><div id="Par36" class="Para"><span class="InlineEquation" id="IEq14"><img src="A468350_1_En_3_Chapter_IEq14.gif" alt="$$H_1$$"/></span> <span class="InlineEquation" id="IEq15"><img src="A468350_1_En_3_Chapter_IEq15.gif" alt="$$_{FAUL}$$"/></span>: BDD is more effective regarding fault detection than UAT.</div><div id="Par37" class="Para"><span class="InlineEquation" id="IEq16"><img src="A468350_1_En_3_Chapter_IEq16.gif" alt="$$H_1$$"/></span> <span class="InlineEquation" id="IEq17"><img src="A468350_1_En_3_Chapter_IEq17.gif" alt="$$_{COME}$$"/></span>: BDD is more effective regarding communication than UAT.</div></div><div id="Sec8" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.4 </span>Variables</h3><div id="Par38" class="Para">The independent variables are the acceptance testing techniques. The dependent variables are: (1) productivity (PROD). It is defined as output per unit effort [<cite><a href="#CR23">23</a></cite>]. In our experiment, the participants test the user stories in the STPA safety report and produce safety test cases. We assess it via the number of implemented (tested) user stories<a href="#Fn10" id="Fn10_source"><sup>10</sup></a> per minute (NIUS) [<cite><a href="#CR23">23</a></cite>]; (2) test thoroughness (THOR). Code coverage is an important measure for the thoroughness of test suites including safety test suites [<cite><a href="#CR27">27</a></cite>]. Considering a low complexity of our provided systems, line coverage (LC) [<cite><a href="#CR26">26</a></cite>] is more suitable than branch coverage (BC); (3) fault detection effectiveness (FAUL). Mutation testing [<cite><a href="#CR25">25</a></cite>] is powerful and effective to indicate the capability at finding faults [<cite><a href="#CR26">26</a></cite>]. In our experiment, we measure how well a safety test suite is able to find faults at the code level. We assess this via a Mutation Score Indicator (MSI) [<cite><a href="#CR26">26</a></cite>]; (4) communication effectiveness (COME). We assess this via a post-questionnaire with 11 questions for developers covering topics like understandability and 13 questions for business analysts covering topics like confidentiality according to Adzic [<cite><a href="#CR35">35</a></cite>]. The results are in a 5-point scale from −2 (negative) to +2 (positive).</div></div><div id="Sec9" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.5 </span>Pilot Study</h3><div id="Par40" class="Para">Six master students majoring in software engineering took part in a pilot study. We arranged a four-hour training program. The first author observed the operation and concluded as follows: (1) The STPA safety report was too complicated to be used by inexperienced students. We used a comprehensive STPA report by using XSTAMPP<a href="#Fn11" id="Fn11_source"><sup>11</sup></a> in the pilot study. However, a lot of unnecessary data, such as accidents, hazards and safety requirements at the system level, influenced the understanding. It costs too much time to capture the information. Thus, we simplified the STPA report with the process variables, algorithms, and UCAs. (2) We used the original Java code from a previous student project. The complex code affected the quick understanding. After the pilot study, we simplified it. (3) Training is extremely important. In the pilot study, one participant had not taken part in the training program, which led to his experiment being unfinished. We provide a textual tutorial and system description for each participant as a backup. (4) We have only used an experiment report to record the measures. However, the pure numbers sometimes cannot show clear causalities. Thus, we use a screen video recording in parallel with the experiment report.</div></div><div id="Sec10" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">4.6 </span>Experiment Operation</h3><div id="Par42" class="Para">As we can see in Fig. <span class="InternalRef"><a href="#Fig3">3</a></span>, we divide the 44 participants into 4 groups. We provide 2 systems and evaluate 2 acceptance testing methods. Group A1 uses BDD for system 1. Group A2 uses BDD for system 2. Group B1 uses UAT for system 1. Group B2 uses UAT for system 2. We use two systems to evaluate the communication between developers and business analysts. The developers are the participants in each group, while the fictional business analysts are portrayed by the participants in the other group using various testing methods and systems.<div class="Figure" id="Fig3"><div class="MediaObject" id="MO3"><img src="A468350_1_En_3_Fig3_HTML.gif" alt="A468350_1_En_3_Fig3_HTML.gif"/></div><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 3.</span><div class="SimplePara">Experiment operation</div></div></div></div>
</div><div id="Par43" class="Para">The experiment consists of 2 phases: <span class="EmphasisTypeItalic">preparation</span> and <span class="EmphasisTypeItalic">operation</span>. The <span class="EmphasisTypeItalic">preparation</span> was run 2 weeks before the experiment to perform the pre-questionnaire and training. The <span class="EmphasisTypeItalic">operation</span> consists of three sessions (30 min/session). In the <span class="InlineEquation" id="IEq18"><img src="A468350_1_En_3_Chapter_IEq18.gif" alt="$$1^{st}$$"/></span> session, four groups write acceptance test cases. Group A1 (BDD) and Group A2 (BDD) write test scenarios in Eclipse with the Jbehave plug-in as a story file. Group B1 (UAT) and Group B2 (UAT) write acceptance criteria in plaintext. We provide 30 unsafe control actions (UCAs) in an STPA safety report. When the students finish all the 30 UCAs in 30 min, they record the time in minutes. After the <span class="InlineEquation" id="IEq19"><img src="A468350_1_En_3_Chapter_IEq19.gif" alt="$$1^{st}$$"/></span> session, the participants record the NIUS and the time in the operation report. In the <span class="InlineEquation" id="IEq20"><img src="A468350_1_En_3_Chapter_IEq20.gif" alt="$$2^{nd}$$"/></span> session, Group A1 (BDD) and Group A2 (BDD) write each test scenario into a test case and run the test case. If it fails, they should modify the trigger (code) and pass the test case. Group B1 (UAT) and Group B2 (UAT) review Java code, execute the test cases manually and complete their acceptance test report. At the end of the <span class="InlineEquation" id="IEq21"><img src="A468350_1_En_3_Chapter_IEq21.gif" alt="$$2^{nd}$$"/></span> session, they run PIT mutation testing. The LC and MSI are generated automatically in the PIT test report. They write down the results in the operation report. In the <span class="InlineEquation" id="IEq22"><img src="A468350_1_En_3_Chapter_IEq22.gif" alt="$$3^{rd}$$"/></span> session, the participant portrays as a developer for 15 min and a business analyst for 15 min. The developer is expected to explain his/her testing strategy as clearly as possible, while the fictional business analyst should try to question the developer. To this end, they answer a post-questionnaire.<div id="Tab2" class="Table"><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Table 2.</span><div class="SimplePara">Descriptive statistic</div></div></div><table border="1"><colgroup><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/><col align="left"/></colgroup><thead><tr class="header"><th align="left"><div class="SimplePara">Measure</div></th><th align="left"><div class="SimplePara">Treatment</div></th><th align="left"><div class="SimplePara">Experiment</div></th><th align="left"><div class="SimplePara">Mean</div></th><th align="left"><div class="SimplePara">St.Dev</div></th><th align="left"><div class="SimplePara">Min</div></th><th align="left"><div class="SimplePara">Median</div></th><th align="left"><div class="SimplePara">Max</div></th><th align="left"><div class="SimplePara">95% CI lower</div></th><th align="left"><div class="SimplePara">95% CI upper</div></th></tr></thead><tbody><tr class="noclass"><td rowspan="4" align="left"><div class="SimplePara">NIUS</div></td><td rowspan="2" align="left"><div class="SimplePara">BDD</div></td><td align="left"><div class="SimplePara">Group A1</div></td><td align="left"><div class="SimplePara">0.52</div></td><td align="left"><div class="SimplePara">0.24</div></td><td align="left"><div class="SimplePara">0.26</div></td><td align="left"><div class="SimplePara">0.45</div></td><td align="left"><div class="SimplePara">1.20</div></td><td align="left"><div class="SimplePara">0.37</div></td><td align="left"><div class="SimplePara">0.66</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group A2</div></td><td align="left"><div class="SimplePara">0.69</div></td><td align="left"><div class="SimplePara">0.19</div></td><td align="left"><div class="SimplePara">0.42</div></td><td align="left"><div class="SimplePara">0.65</div></td><td align="left"><div class="SimplePara">1.00</div></td><td align="left"><div class="SimplePara">0.58</div></td><td align="left"><div class="SimplePara">0.80</div></td></tr><tr class="noclass"><td rowspan="2" align="left"><div class="SimplePara">UAT</div></td><td align="left"><div class="SimplePara">Group B1</div></td><td align="left"><div class="SimplePara">0.58</div></td><td align="left"><div class="SimplePara">0.22</div></td><td align="left"><div class="SimplePara">0.33</div></td><td align="left"><div class="SimplePara">0.57</div></td><td align="left"><div class="SimplePara">1.00</div></td><td align="left"><div class="SimplePara">0.45</div></td><td align="left"><div class="SimplePara">0.71</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group B2</div></td><td align="left"><div class="SimplePara">0.67</div></td><td align="left"><div class="SimplePara">0.29</div></td><td align="left"><div class="SimplePara">0.27</div></td><td align="left"><div class="SimplePara">0.60</div></td><td align="left"><div class="SimplePara">1.20</div></td><td align="left"><div class="SimplePara">0.50</div></td><td align="left"><div class="SimplePara">0.84</div></td></tr><tr class="noclass"><td rowspan="4" align="left"><div class="SimplePara">LC</div></td><td rowspan="2" align="left"><div class="SimplePara">BDD</div></td><td align="left"><div class="SimplePara">Group A1</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.05</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.03</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group A2</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.04</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.03</div></td></tr><tr class="noclass"><td rowspan="2" align="left"><div class="SimplePara">UAT</div></td><td align="left"><div class="SimplePara">Group B1</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.03</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.02</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group B2</div></td><td align="left"><div class="SimplePara">0.02</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.03</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">0.02</div></td></tr><tr class="noclass"><td rowspan="4" align="left"><div class="SimplePara">MSI</div></td><td rowspan="2" align="left"><div class="SimplePara">BDD</div></td><td align="left"><div class="SimplePara">Group A1</div></td><td align="left"><div class="SimplePara">0.90</div></td><td align="left"><div class="SimplePara">0.38</div></td><td align="left"><div class="SimplePara">0.36</div></td><td align="left"><div class="SimplePara">1.00</div></td><td align="left"><div class="SimplePara">1.33</div></td><td align="left"><div class="SimplePara">0.67</div></td><td align="left"><div class="SimplePara">1.13</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group A2</div></td><td align="left"><div class="SimplePara">0.93</div></td><td align="left"><div class="SimplePara">0.49</div></td><td align="left"><div class="SimplePara">0.44</div></td><td align="left"><div class="SimplePara">0.83</div></td><td align="left"><div class="SimplePara">2.17</div></td><td align="left"><div class="SimplePara">0.63</div></td><td align="left"><div class="SimplePara">1.22</div></td></tr><tr class="noclass"><td rowspan="2" align="left"><div class="SimplePara">UAT</div></td><td align="left"><div class="SimplePara">Group B1</div></td><td align="left"><div class="SimplePara">0.89</div></td><td align="left"><div class="SimplePara">0.36</div></td><td align="left"><div class="SimplePara">0.42</div></td><td align="left"><div class="SimplePara">0.88</div></td><td align="left"><div class="SimplePara">1.56</div></td><td align="left"><div class="SimplePara">0.67</div></td><td align="left"><div class="SimplePara">1.10</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group B2</div></td><td align="left"><div class="SimplePara">0.85</div></td><td align="left"><div class="SimplePara">0.46</div></td><td align="left"><div class="SimplePara">0.30</div></td><td align="left"><div class="SimplePara">0.65</div></td><td align="left"><div class="SimplePara">1.63</div></td><td align="left"><div class="SimplePara">0.58</div></td><td align="left"><div class="SimplePara">1.12</div></td></tr><tr class="noclass"><td rowspan="4" align="left"><div class="SimplePara">COME</div></td><td rowspan="2" align="left"><div class="SimplePara">BDD</div></td><td align="left"><div class="SimplePara">Group A1</div></td><td align="left"><div class="SimplePara">1.27</div></td><td align="left"><div class="SimplePara">0.81</div></td><td align="left"><div class="SimplePara">−2.00</div></td><td align="left"><div class="SimplePara">
                              <span class="EmphasisTypeBold">1.50</span>
                            </div></td><td align="left"><div class="SimplePara">2.00</div></td><td align="left"><div class="SimplePara">0.79</div></td><td align="left"><div class="SimplePara">1.75</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group A2</div></td><td align="left"><div class="SimplePara">1.18</div></td><td align="left"><div class="SimplePara">0.70</div></td><td align="left"><div class="SimplePara">−1.00</div></td><td align="left"><div class="SimplePara">
                              <span class="EmphasisTypeBold">1.00</span>
                            </div></td><td align="left"><div class="SimplePara">2.00</div></td><td align="left"><div class="SimplePara">0.76</div></td><td align="left"><div class="SimplePara">1.58</div></td></tr><tr class="noclass"><td rowspan="2" align="left"><div class="SimplePara">UAT</div></td><td align="left"><div class="SimplePara">Group B1</div></td><td align="left"><div class="SimplePara">−0.05</div></td><td align="left"><div class="SimplePara">1.20</div></td><td align="left"><div class="SimplePara">−2.00</div></td><td align="left"><div class="SimplePara">
                              <span class="EmphasisTypeBold">0.00</span>
                            </div></td><td align="left"><div class="SimplePara">2.00</div></td><td align="left"><div class="SimplePara">−0.75</div></td><td align="left"><div class="SimplePara">0.66</div></td></tr><tr class="noclass"><td align="left"><div class="SimplePara">Group B2</div></td><td align="left"><div class="SimplePara">0.01</div></td><td align="left"><div class="SimplePara">1.13</div></td><td align="left"><div class="SimplePara">−2.00</div></td><td align="left"><div class="SimplePara">
                              <span class="EmphasisTypeBold">0.50</span>
                            </div></td><td align="left"><div class="SimplePara">2.00</div></td><td align="left"><div class="SimplePara">−0.67</div></td><td align="left"><div class="SimplePara">0.67</div></td></tr></tbody></table><div class="TableFooter"><div class="SimplePara">Note: St. Dev means standard deviation; CI means confidence interval. NIUS means number of implemented (tested) user stories per minute. LC means line coverage. MSI means mutation score indicator. COME was assessed via questionnaire with the results in a 5-point scale from −2 (negative) to +2 (positive).</div></div></div>
</div><div id="Par44" class="Para">
                  <div class="Figure" id="Fig4"><div class="MediaObject" id="MO4"><img src="A468350_1_En_3_Fig4_HTML.gif" alt="A468350_1_En_3_Fig4_HTML.gif"/></div><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 4.</span><div class="SimplePara">Boxplot for PROD, THOR and FAUL</div></div></div></div>
                  <div class="Figure" id="Fig5"><div class="MediaObject" id="MO5"><img src="A468350_1_En_3_Fig5_HTML.gif" alt="A468350_1_En_3_Fig5_HTML.gif"/></div><div class="Caption" xml:lang="en"><div class="CaptionContent"><span class="CaptionNumber">Fig. 5.</span><div class="SimplePara">Alluvial diagram for communication effectiveness</div></div></div></div>
                </div></div></div><div id="Sec11" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">5 </span>Analysis</h2><div id="Sec12" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">5.1 </span>Descriptive Analysis</h3><div id="Par45" class="Para">In Table <span class="InternalRef"><a href="#Tab2">2</a></span>, we summarize the descriptive statistics of the gathered measures<a href="#Fn12" id="Fn12_source"><sup>12</sup></a>. To sum up, the results from the two systems in one treatment are almost identical. BDD and UAT have only small differences regarding NIUS and MSI. However, COME in BDD (Mean = 1.27, 1.18; Std.Dev = 0.81, 0.70) and UAT (Mean = −0.05, 0.01; Std.Dev = 1.20, 1.13) differ more strongly. LC has a small difference. In Fig. <span class="InternalRef"><a href="#Fig4">4</a></span>, we show a clear comparison and can see some outliers concerning LC. In Fig. <span class="InternalRef"><a href="#Fig5">5</a></span>, we use an alluvial diagram to show COME. We can conclude that BDD has a better communication effectiveness than UAT from the perspective of developers and business analysts respectively (depending on the length of black vertical bar on the right side of Fig. <span class="InternalRef"><a href="#Fig5">5</a></span>(a) and (b)). On the left side, we list 24 sub-aspects of assessing the communication effectiveness. The boldness of the colorful lines indicates the degree of impact. A thicker line has a larger impact on each aspect. We can see six noteworthy values from Fig. <span class="InternalRef"><a href="#Fig5">5</a></span>(a) that BDD is better than UAT: (4) Test cases have a clear documentation. (5) They could flush out the functional gaps before development. (6) They have a good understanding of business requirements. (7) Test cases have a good organization and structure. (8) Realistic examples make them think harder. (11) There is an obvious glue between test cases and code. From Fig. <span class="InternalRef"><a href="#Fig5">5</a></span>(b), five noteworthy values show that BDD is better than UAT: (6) The developers consider safety requirements deeply and initially. (8) It is easy to identify conflicts in business rules and test cases. (9) They are confident about the test cases. (12) They are clear about the status of acceptance testing. (13) They could spend less time on sprint-end acceptance testing but more in parallel with development. In addition, the other aspects show also slightly better results when using BDD than UAT.</div></div><div id="Sec13" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">5.2 </span>Hypothesis Testing</h3><div id="Par47" class="Para">To start with, we evaluate the pre-questionnaire. No statistically significant differences between BDD and UAT groups are found concerning Java programming, acceptance testing, knowledge on SCS and agile techniques (t-test, <span class="InlineEquation" id="IEq23"><img src="A468350_1_En_3_Chapter_IEq23.gif" alt="$$\alpha $$"/></span> = 0.05, p &gt; 0.05 for all test parameters). Furthermore, we test the normality of the data distribution with Kolmogorov-Smirnov and Shapiro-Wilk tests at <span class="InlineEquation" id="IEq24"><img src="A468350_1_En_3_Chapter_IEq24.gif" alt="$$\alpha $$"/></span> = 0.05. The results show that the data for NIUS in Group A1, for LC in Group A1, A2, B2 and for MSI in Group A1, A2 are not normally distributed. Thus, we use non-parametric tests in the analysis. In addition to the use of p-values for hypotheses testing (<span class="InlineEquation" id="IEq25"><img src="A468350_1_En_3_Chapter_IEq25.gif" alt="$$\alpha $$"/></span> = 0.05, one-tailed) from the Mann-Whitney test, Wilcoxon test and ANOVA test, we include the effect size Cohen’s d. Since we expect BDD to be better than UAT, we use one-tailed tests. NIUS is not significantly affected by using the BDD or the UAT approach (system 1: p=0.206; system 2: p = 0.359, non-significant). LC is not significantly affected by using BDD or UAT (system 1: p = 0.057; system 2: p = 0.051, non-significant). MSI shows no statistically significant difference between using BDD or UAT (system 1: p = 0.472; system 2: p = 0.359, non-significant). However, COME is significantly different (system 1: p &lt; 0.00001; system 2: p &lt; 0.00001, significant). We accept the alternative hypothesis that BDD shows better communication effectiveness than UAT. Cohen’s d shows the values around 0.2, which signifies small effects, around 0.5 stands for medium effects and around 0.8 for large effects. Thus, for COME, system 1 shows a large effect (d = 2.908). For LC we have both medium effects (system 1: d = 0.684; system 2: d = 0.662). The rest of the effects are small.</div></div></div><div id="Sec14" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">6 </span>Threats to Validity</h2><div id="Sec15" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">6.1 </span>Internal Validity</h3><div id="Par48" class="Para"><span class="EmphasisTypeItalic">First</span>, note that we have four groups in our experiment. To avoid a multiple group threat, we prepare a pre-questionnaire to investigate the students’ background knowledge. The results of the t-tests show no statistically significant differences among the groups concerning each measure. <span class="EmphasisTypeItalic">Second</span>, concerning the instrument, UAT is faster to learn than BDD regarding the use of tools. Even though we provide a training to narrow the gap, the <span class="EmphasisTypeItalic">productivity</span> might have been influenced, since the students have to get familiar with the hierarchy of writing test suites in a BDD tool. The artifacts, such as tutorials and operation report, are designed respectively with the same structure to avoid threats. In addition to the observation, we save the participants’ workspaces after the experiment and video recordings for deep analysis. <span class="EmphasisTypeItalic">Third</span>, the students majoring in software engineering might identify more with the developer role than the business analyst role. Thus, we design two comparable systems. The students in each pair use different systems and test approaches to reduce the influence of prior knowledge. Moreover, we provide a reference [<cite><a href="#CR36">36</a></cite>] on how to perform as a business analyst in an agile project. We also mention their responsibilities in the training.</div></div><div id="Sec16" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">6.2 </span>Construct Validity</h3><div id="Par49" class="Para"><span class="EmphasisTypeItalic">First</span>, the execution of BDD is a variant. BDD should begin with writing tests before coding. However, in our experiment, we use BDD for test-last acceptance testing rather than test-driven design. Thus, we provide source code with mutants. The measures we used could be influenced. In BDD test-first, we write failing test cases first and work on passing all of them to drive coding. According to [<cite><a href="#CR39">39</a></cite>, <cite><a href="#CR41">41</a></cite>], BDD test-first might be as effective as or even more effective than BDD test-last. <span class="EmphasisTypeItalic">Second</span>, the evaluation concerning productivity, test thoroughness, fault detection effectiveness and communication effectiveness does not seem to be enough. As far as we know, our study is the first controlled experiment on BDD. We can base our measurement (PROD, THOR, FAUL) mainly on TDD controlled experiments and some limited experiments on safety verification. There might be better ways to capture how well safety is handled in testing.</div></div><div id="Sec17" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">6.3 </span>Conclusion Validity</h3><div id="Par50" class="Para"><span class="EmphasisTypeItalic">First</span>, concerning violated assumptions of statistical tests, the Mann-Whitney U-test is robust when the sample size is approximately 20. For each treatment, we have 22 students. Moreover, we use Wilcoxon W test as well as Z to increase the robustness. Nevertheless, under certain conditions, non-parametric rank-based tests can themselves lack robustness [<cite><a href="#CR44">44</a></cite>]. <span class="EmphasisTypeItalic">Second</span>, concerning random heterogeneity of subjects, we arranged them based on the Java programming experience. According to the pre-questionnaire, the students are from the same course and 88.6% of them are in the same major.</div></div><div id="Sec18" class="Section2 RenderAsSection2"><h3 class="Heading"><span class="HeadingNumber">6.4 </span>External Validity</h3><div id="Par51" class="Para"><span class="EmphasisTypeItalic">First</span>, the subjects are students. Although there are some skilled students who could perform as well as experts, most of them lack professional experience. This consideration may limit the generalization of the results. To consider this debatable issue in terms of using students as subjects, we refer to [<cite><a href="#CR33">33</a></cite>]. They said: conducting experiments with professionals as a first step should not be encouraged unless high sample sizes are guaranteed. In addition, a long learning cycle and a new technology are two hesitations for using professionals. STPA was developed in 2012, so there is still a lack of experts on the industrial level. BDD has not been used for verifying safety requirements. Thus, we believe that using students as subjects is a suitable way to aggregate contributions in our research area. We also refer to a study by Cleland-Huang and Rahimi, which successfully ran an SCS project with graduate students [<cite><a href="#CR2">2</a></cite>]. <span class="EmphasisTypeItalic">Second</span>, the simplicity of the tasks poses a threat. We expect to keep the difficulty of the tasks in accordance with the capability of students. Nevertheless, the settings are not fully representative of a real-world project.</div></div></div><div id="Sec19" class="Section1 RenderAsSection1"><h2 class="Heading"><span class="HeadingNumber">7 </span>Discussion and Conclusion</h2><div id="Par52" class="Para">The main benefit of our research is that we propose a possible way to use BDD for safety verification with STPA for safety analysis in agile development. We validate the combination in a controlled experiment with the limitation that we used BDD only in a test-last way. The experiment shows some remarkable results. The <span class="EmphasisTypeItalic">productivity</span> has no statistically significant difference between BDD and UAT. That contradicts our original expectation. We would expect BDD, as an automated testing method, to be more productive than manual UAT. Yet, as the students are not experts in our experiment, they need considerable time to get familiar with the BDD tool. The students use Jbehave to write BDD test cases in our experiment, which has strict constraints on hierarchy and naming conventions to connect test scenarios with test cases. UAT should be easier to learn. We therefore analyzed our video recordings and found that BDD developers use nearly 25% to 50% of their time to construct the hierarchy and naming. Scanniello et al. [<cite><a href="#CR37">37</a></cite>] also mentioned this difficulty when students apply TDD. In the future, we plan to use skilled professionals in test automation to replicate this study. This could lead to different results. The <span class="EmphasisTypeItalic">test thoroughness</span> and <span class="EmphasisTypeItalic">fault detection effectiveness</span> show a non-significant difference between BDD and UAT. We could imagine that our provided Java code is too simplified to show a significant difference. The mutants are easily found with a review. These aspects need further research.</div><div id="Par53" class="Para">The <span class="EmphasisTypeItalic">communication effectiveness</span> shows better results by using BDD than UAT on 24 aspects. We highlight 11 significant aspects. The <span class="EmphasisTypeItalic">developers</span> found that: <span class="EmphasisTypeBold">BDD has a clear documentation.</span> A clear documentation of acceptance test cases is important for communication [<cite><a href="#CR42">42</a></cite>]. The scenarios are written in plain English with no hidden test instrumentation. The given-when-then format is clear for describing test scenarios for safety verification based on system theory. <span class="EmphasisTypeBold">The developers using BDD could flush out functional gaps before development.</span> The communication concerning safety could happen at the beginning of the development. They discuss safety requirements with the business analysts and spot the detailed challenges or edge cases before functional development. UAT happens mostly at the end of the development. It makes the rework expensive and is easy to be cut in safety-critical systems. <span class="EmphasisTypeBold">The developers using BDD have a good understanding of the business requirements.</span> A good understanding of safety requirements helps an effective communication. They could build a shared understanding in the “3 Amigos Meeting” to ensure that their ideas about the safety requirements are consistent with the business analysts. The developers using UAT might understand safety requirements with a possible bias. <span class="EmphasisTypeBold">BDD test cases have a good organization and structure.</span> This makes the test cases easy to understand, especially during maintenance. They include strict naming conventions and a clear hierarchy to manage test scenarios and test cases. <span class="EmphasisTypeBold">Realistic examples in BDD make the developers think harder.</span> The safety requirements are abstract with possibly cognitive diversity, which leave a lot of space for ambiguity and misunderstanding. That negatively influences effective communication. Realistic examples give us a much better way to explain how safe scenarios really work than pure safety requirements do. <span class="EmphasisTypeBold">There is an obvious glue between BDD test cases and code.</span> There is glue code in BDD safety verification, which allows an effective separation between safety requirements and implementation details. This glue code supports the understanding and even communication between business analysts and developers. In addition, it ensures the bidirectional traceability between safety requirements and test cases. The <span class="EmphasisTypeItalic">business analysts</span> thought that: <span class="EmphasisTypeBold">The developers using BDD consider the safety requirements deeply and initiatively.</span> The collaboration promotes a sense of ownership of the deliverable products. That increases an initiative communication. Instead of passively reading the documents, the developers participate in the discussion about writing test scenarios and are more committed to them. <span class="EmphasisTypeBold">The business analysts are more confident about the BDD test cases.</span> Confidence promotes effective communication [<cite><a href="#CR43">43</a></cite>]. The business analysts could give a big picture with safety goals to the developers. Feedback from developers and their realistic unsafe scenarios give the business analysts confidence that the developers understand the safety goals correctly. <span class="EmphasisTypeBold">It is easy to identify conflicts in business rules and test cases when using BDD.</span> BDD has a set of readable test scenarios focusing on business rules (safety requirements). Each test scenario and test case are directly connected to the code. The business analysts can pull out test cases related to a particular business rule. This helps communication, especially when there is a changing request. <span class="EmphasisTypeBold">The business analysts are clear about the status of acceptance testing when using BDD.</span> It promotes a state-of-art communication. That can be attributed to the automated test suites, which might be connected with a continuous integration server and a project management tool to receive a verification report automatically. <span class="EmphasisTypeBold">The business analysts could spend less time on sprint-end acceptance tests but more in parallel with development.</span> They can verify the safety requirements periodically and therefore enhance communication throughout the project.</div><div id="Par54" class="Para">In conclusion, to some extent, BDD is an effective method for verifying safety requirements in agile development. As this is the first experiment investigating BDD for safety verification, further empirical research is needed to check our results. We invite replications of this experiment using our replication package<a href="#Fn13" id="Fn13_source"><sup>13</sup></a>.</div></div><div class="License LicenseSubType-cc-by"><a href="https://creativecommons.org/licenses/by/4.0"><img src="cc-by.png" alt="Creative Commons"/></a><div class="SimplePara">Open Access This chapter is licensed under the terms of the Creative Commons Attribution 4.0 International License (http://creativecommons.org/licenses/by/4.0/), which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license and indicate if changes were made.
The images or other third party material in this book are included in the book's Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the book's Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder.</div></div><div class="Bibliography" id="Bib1"><div class="Heading">References</div><div class="BibliographyWrapper"><div class="Citation"><div class="CitationNumber">1.</div><div class="CitationContent" id="CR1">Dybå, T., Dingsøyr, T.: Empirical studies of agile software development: A systematic review. Inf. Softw. Technol. <span class="EmphasisTypeBold">50</span>(9–10), 833–859 (2008)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1016/j.infsof.2008.01.006"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">2.</div><div class="CitationContent" id="CR2">Cleland-Huang, J., Rahimi, M.: A case study: injecting safety-critical thinking into graduate software engineering projects. In: Proceedings of the 39th International Conference on Software Engineering: Software Engineering and Education Track. IEEE (2017)</div></div><div class="Citation"><div class="CitationNumber">3.</div><div class="CitationContent" id="CR3">Arthur, J.D., Dabney, J.B.: Applying standard independent verification and validation (IV&amp;V) techniques within an Agile framework: is there a compatibility issue? In: Proceedings of Systems Conference. IEEE (2017)</div></div><div class="Citation"><div class="CitationNumber">4.</div><div class="CitationContent" id="CR4">Fleming, C.: Safety-driven early concept analysis and development. Dissertation. Massachusetts Institute of Technology (2015)</div></div><div class="Citation"><div class="CitationNumber">5.</div><div class="CitationContent" id="CR5">Wang, Y., Wagner, S.: Toward integrating a system theoretic safety analysis in an agile development process. In: Proceedings of Software Engineering, Workshop on Continuous Software Engineering (2016)</div></div><div class="Citation"><div class="CitationNumber">6.</div><div class="CitationContent" id="CR6">Leveson, N.: Engineering a Safer World: Systems Thinking Applied to Safety. MIT Press, Cambridge (2011)</div></div><div class="Citation"><div class="CitationNumber">7.</div><div class="CitationContent" id="CR7">Wang, Y., Wagner, S.: Towards applying a safety analysis and verification method based on STPA to agile software development. In: IEEE/ACM International Workshop on Continuous Software Evolution and Delivery. IEEE (2016)</div></div><div class="Citation"><div class="CitationNumber">8.</div><div class="CitationContent" id="CR8">Martins, L.E., Gorschek, T.: Requirements engineering for safety-critical systems: overview and challenges. IEEE Softw. <span class="EmphasisTypeBold">34</span>(4), 49–57 (2017)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1109/MS.2017.94"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">9.</div><div class="CitationContent" id="CR9">Vuori, M.: Agile development of safety-critical software. Tampere University of Technology, Department of Software Systems (2011)</div></div><div class="Citation"><div class="CitationNumber">10.</div><div class="CitationContent" id="CR10">Stålhane, T., Myklebust, T., Hanssen, G.K.: The application of Safe Scrum to IEC 61508 certifiable software. In: Proceedings of the 11th International Probabilistic Safety Assessment and Management Conference and the Annual European Safety and Reliability Conference (2012)</div></div><div class="Citation"><div class="CitationNumber">11.</div><div class="CitationContent" id="CR11">Ge, X., Paige, R.F., McDermid, J.A.: An iterative approach for development of safety-critical software and safety arguments. In: Proceedings of Agile Conference. IEEE (2010)</div></div><div class="Citation"><div class="CitationNumber">12.</div><div class="CitationContent" id="CR12">Wang, Y., Ramadani, J., Wagner, S.: An exploratory study of applying a Scrum development process for safety-critical systems. In: Proceedings of the 18th International Conference on Product-Focused Software Process Improvement (2017)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-319-69926-4_23"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">13.</div><div class="CitationContent" id="CR13">Eleftherakis, G., Cowling, A.J.: An agile formal development methodology. In: Proceedings of the 1st South-East European Workshop on Formal Methods (2003)</div></div><div class="Citation"><div class="CitationNumber">14.</div><div class="CitationContent" id="CR14">Ghezzi, C., et al.: On requirements verification for model refinements. In: Proceedings of Requirements Engineering Conference. IEEE (2013)</div></div><div class="Citation"><div class="CitationNumber">15.</div><div class="CitationContent" id="CR15">Wynne, M., Hellesoy, A.: The Cucumber Book: Behaviour-Driven Development for Testers and Developers. Pragmatic Bookshelf, Dallas (2012)</div></div><div class="Citation"><div class="CitationNumber">16.</div><div class="CitationContent" id="CR16">Smart, J.F.: BDD in Action: Behavior-Driven Development for the Whole Software Lifecycle. Manning, New York (2015)</div></div><div class="Citation"><div class="CitationNumber">17.</div><div class="CitationContent" id="CR17">Silva, T.R., Hak, J.L., Winckler, M.: A behavior-based ontology for supporting automated assessment of interactive systems. In: Proceedings of the 11th International Conference on Semantic Computing. IEEE (2017)</div></div><div class="Citation"><div class="CitationNumber">18.</div><div class="CitationContent" id="CR18">Hummel, M., Rosenkranz, C., Holten, R.: The role of communication in agile systems development. Bus. Inf. Syst. Eng. <span class="EmphasisTypeBold">5</span>(5), 343–355 (2013)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/s12599-013-0282-4"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">19.</div><div class="CitationContent" id="CR19">Okubo, T., et al.: Security and privacy behavior definition for behavior driven development. In: Proceedings of the 15th International Conference on Product-Focused Software Process Improvement (2014)</div></div><div class="Citation"><div class="CitationNumber">20.</div><div class="CitationContent" id="CR20">Lai, S.T., Leu, F.Y., Chu, W.: Combining IID with BDD to enhance the critical quality of security functional requirements. In: Proceedings of the 9th International Conference on Broadband and Wireless Computing, Communication and Applications. IEEE (2014)</div></div><div class="Citation"><div class="CitationNumber">21.</div><div class="CitationContent" id="CR21">Fucci, D., Turhan, B.: A replicated experiment on the effectiveness of test-first development. In: Proceedings of the International Symposium on Empirical Software Engineering and Measurement. IEEE (2013)</div></div><div class="Citation"><div class="CitationNumber">22.</div><div class="CitationContent" id="CR22">Fucci, D., et al.: A dissection of test-driven development: does it really matter to test-first or to test-last? IEEE Trans. Software Eng. <span class="EmphasisTypeBold">43</span>(7), 597–614 (2017)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1109/TSE.2016.2616877"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">23.</div><div class="CitationContent" id="CR23">Erdogmus, H., Morisio, M., Torchiano, M.: On the effectiveness of the test-first approach to programming. IEEE Trans. Software Eng. <span class="EmphasisTypeBold">31</span>(3), 226–237 (2005)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1109/TSE.2005.37"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">24.</div><div class="CitationContent" id="CR24">Kollanus, S., Isomöttönen, V.: Understanding TDD in academic environment: experiences from two experiments. In: Proceedings of the 8th International Conference on Computing Education Research. ACM (2008)</div></div><div class="Citation"><div class="CitationNumber">25.</div><div class="CitationContent" id="CR25">Hamlet, R.G.: Testing programs with the aid of a compiler. IEEE Trans. Software Eng. <span class="EmphasisTypeBold">4</span>, 279–290 (1977)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1109/TSE.1977.231145"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">26.</div><div class="CitationContent" id="CR26">Madeyski, L.: The impact of test-first programming on branch coverage and mutation score indicator of unit tests: an experiment. Inf. Softw. Technol. <span class="EmphasisTypeBold">52</span>(2), 169–184 (2010)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1016/j.infsof.2009.08.007"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">27.</div><div class="CitationContent" id="CR27">Marick, B.: How to misuse code coverage. In: Proceedings of the 16th International Conference on Testing Computer Software (1999)</div></div><div class="Citation"><div class="CitationNumber">28.</div><div class="CitationContent" id="CR28">Pančur, M., Ciglarič, M.: Impact of test-driven development on productivity, code and tests: a controlled experiment. Inf. Softw. Technol. <span class="EmphasisTypeBold">53</span>(6), 557–573 (2011)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1016/j.infsof.2011.02.002"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">29.</div><div class="CitationContent" id="CR29">George, B., Williams, L.: A structured experiment of test-driven development. Inf. Softw. Technol. <span class="EmphasisTypeBold">46</span>(5), 337–342 (2004)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1016/j.infsof.2003.09.011"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">30.</div><div class="CitationContent" id="CR30">Siniaalto, M., Abrahamsson, P.: A comparative case study on the impact of test-driven development on program design and test coverage. In: Proceedings of 1st International Symposium on Empirical Software Engineering and Measurement (2007)</div></div><div class="Citation"><div class="CitationNumber">31.</div><div class="CitationContent" id="CR31">North, D.: JBehave. A framework for behaviour driven development (2012)</div></div><div class="Citation"><div class="CitationNumber">32.</div><div class="CitationContent" id="CR32">Wohlin, C., et al.: Experimentation in Software Engineering. Springer, Heidelberg (2012). <span class="ExternalRef"><a href="https://doi.org/10.1007/978-3-642-29044-2"><span class="RefSource">https://​doi.​org/​10.​1007/​978-3-642-29044-2</span></a></span><span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/978-3-642-29044-2"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">33.</div><div class="CitationContent" id="CR33">Falessi, D., et al.: Empirical software engineering experts on the use of students and professionals in experiments. Empirical Softw. Eng. <span class="EmphasisTypeBold">23</span>(1), 452–489 (2018)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/s10664-017-9523-3"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">34.</div><div class="CitationContent" id="CR34">Enoiu, E.P., et al.: A controlled experiment in testing of safety-critical embedded software. In: Proceedings of the International Conference on Software Testing, Verification and Validation. IEEE (2016)</div></div><div class="Citation"><div class="CitationNumber">35.</div><div class="CitationContent" id="CR35">Adzic, G.: Bridging the Communication Gap: Specification by Example and Agile Acceptance Testing. Neuri Limited, London (2009)</div></div><div class="Citation"><div class="CitationNumber">36.</div><div class="CitationContent" id="CR36">Gregorio, D.: How the business analyst supports and encourages collaboration on agile projects. In: Proceedings of International Systems Conference. IEEE (2012)</div></div><div class="Citation"><div class="CitationNumber">37.</div><div class="CitationContent" id="CR37">Scanniello, G., et al.: Students’ and professionals’ perceptions of test-driven development: a focus group study. In: Proceedings of the 31st Annual Symposium on Applied Computing. ACM (2016)</div></div><div class="Citation"><div class="CitationNumber">38.</div><div class="CitationContent" id="CR38">Crispin, L., Gregory, J.: Agile Testing: A Practical Guide for Testers and Agile Teams. Pearson Education, Boston (2009)</div></div><div class="Citation"><div class="CitationNumber">39.</div><div class="CitationContent" id="CR39">Huang, L., Holcombe, M.: Empirical investigation towards the effectiveness of Test First programming. Inf. Softw. Technol. <span class="EmphasisTypeBold">51</span>(1), 182–194 (2009)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1016/j.infsof.2008.03.007"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">40.</div><div class="CitationContent" id="CR40">Madeyski, L.: Impact of pair programming on thoroughness and fault detection effectiveness of unit test suites. Softw. Process: Improv. Pract. <span class="EmphasisTypeBold">13</span>(3), 281–295 (2008)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1002/spip.382"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">41.</div><div class="CitationContent" id="CR41">Rafique, Y., Mišić, V.B.: The effects of test-driven development on external quality and productivity: a meta-analysis. IEEE Trans. Software Eng. <span class="EmphasisTypeBold">39</span>(6), 835–856 (2013)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1109/TSE.2012.28"><span><span>Crossref</span></span></a></span></span></div></div><div class="Citation"><div class="CitationNumber">42.</div><div class="CitationContent" id="CR42">Haugset, B., Stålhane, T.: Automated acceptance testing as an agile requirements engineering practice. In: Proceedings of the 45th Hawaii International Conference on System Science. IEEE (2012)</div></div><div class="Citation"><div class="CitationNumber">43.</div><div class="CitationContent" id="CR43">Adler, R.B.: Confidence in Communication: A Guide to Assertive and Social Skills. Harcourt School (1977)</div></div><div class="Citation"><div class="CitationNumber">44.</div><div class="CitationContent" id="CR44">Kitchenham, B., et al.: Robust statistical methods for empirical software engineering. Empirical Softw. Eng. <span class="EmphasisTypeBold">22</span>(2), 579–630 (2017)<span class="Occurrences"><span class="Occurrence OccurrenceDOI"><a href="https://doi.org/10.1007/s10664-016-9437-5"><span><span>Crossref</span></span></a></span></span></div></div></div></div><div class="FootnoteSection"><div class="Heading">Footnotes</div><div class="Footnote" id="Fn1"><span class="FootnoteNumber"><a href="#Fn1_source">1</a></span><div class="FootnoteParas"><div id="Par5" class="Para">Low-level BDD is possible to define low-level specifications and interwined with TDD [<cite><a href="#CR16">16</a></cite>].</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn2"><span class="FootnoteNumber"><a href="#Fn2_source">2</a></span><div class="FootnoteParas"><div id="Par12" class="Para">Since we focus on safety in our research, we assign a safety analyst as the QA role in our context.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn3"><span class="FootnoteNumber"><a href="#Fn3_source">3</a></span><div class="FootnoteParas"><div id="Par13" class="Para">More descriptions of STPA for safety analysis are given in [<cite><a href="#CR7">7</a></cite>] concerning an example of using STPA in an airbag system and [<cite><a href="#CR12">12</a></cite>] concerning the use of STPA in a Scrum development process.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn4"><span class="FootnoteNumber"><a href="#Fn4_source">4</a></span><div class="FootnoteParas"><div id="Par15" class="Para">We illustrate a BDD test scenario using only three basic steps “Given” “When” “Then”. More annotations, such as “And”, can also be added.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn5"><span class="FootnoteNumber"><a href="#Fn5_source">5</a></span><div class="FootnoteParas"><div id="Par17" class="Para">We have a limitation in our experiment that we execute BDD only in a test-last way. More discussion of this issue can be found in Sect. <span class="InternalRef"><a href="#Sec16">6.2</a></span>.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn6"><span class="FootnoteNumber"><a href="#Fn6_source">6</a></span><div class="FootnoteParas"><div id="Par18" class="Para">To execute a standard UAT, we mainly refer to [<cite><a href="#CR38">38</a></cite>] with fictional business analysts.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn7"><span class="FootnoteNumber"><a href="#Fn7_source">7</a></span><div class="FootnoteParas"><div id="Par25" class="Para"><span class="ExternalRef"><a href="http://testablelejos.sourceforge.net/"><span class="RefSource">http://​testablelejos.​sourceforge.​net/​</span></a></span>.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn8"><span class="FootnoteNumber"><a href="#Fn8_source">8</a></span><div class="FootnoteParas"><div id="Par26" class="Para"><span class="ExternalRef"><a href="http://jbehave.org/eclipse-integration.html"><span class="RefSource">http://​jbehave.​org/​eclipse-integration.​html</span></a></span>.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn9"><span class="FootnoteNumber"><a href="#Fn9_source">9</a></span><div class="FootnoteParas"><div id="Par27" class="Para"><span class="ExternalRef"><a href="http://pitest.org/"><span class="RefSource">http://​pitest.​org/​</span></a></span>.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn10"><span class="FootnoteNumber"><a href="#Fn10_source">10</a></span><div class="FootnoteParas"><div id="Par39" class="Para">In this article, user stories are safety-related user stories.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn11"><span class="FootnoteNumber"><a href="#Fn11_source">11</a></span><div class="FootnoteParas"><div id="Par41" class="Para"><span class="ExternalRef"><a href="http://www.xstampp.de/"><span class="RefSource">http://​www.​xstampp.​de/​</span></a></span>.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn12"><span class="FootnoteNumber"><a href="#Fn12_source">12</a></span><div class="FootnoteParas"><div id="Par46" class="Para">Raw data is available online: <span class="ExternalRef"><a href="https://doi.org/10.5281/zenodo.1154350"><span class="RefSource">https://​doi.​org/​10.​5281/​zenodo.​1154350</span></a></span>.</div></div><div class="ClearBoth"> </div></div><div class="Footnote" id="Fn13"><span class="FootnoteNumber"><a href="#Fn13_source">13</a></span><div class="FootnoteParas"><div id="Par55" class="Para"><span class="ExternalRef"><a href="https://doi.org/10.5281/zenodo.846976"><span class="RefSource">https://​doi.​org/​10.​5281/​zenodo.​846976</span></a></span>.</div></div><div class="ClearBoth"> </div></div></div></div></body></html>
